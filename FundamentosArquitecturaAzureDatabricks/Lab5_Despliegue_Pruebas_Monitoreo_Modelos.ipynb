{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed5f143",
   "metadata": {},
   "source": [
    "## Parte 1: Batch Scoring - Predicciones por Lotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea837c4",
   "metadata": {},
   "source": [
    "### 1.1 Cargar Modelo desde MLflow Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import struct, col\n",
    "import pandas as pd\n",
    "\n",
    "# Configurar MLflow\n",
    "mlflow.set_registry_uri(\"databricks\")\n",
    "\n",
    "# Nombre del modelo y versi√≥n (del Lab 4)\n",
    "model_name = \"energy_classifier_rf_optimized\"  # Modelo de clasificaci√≥n de consumo energ√©tico\n",
    "model_version = \"Staging\"  # Usar el modelo en Staging del Lab 4\n",
    "\n",
    "# Cargar modelo\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "print(f\"Cargando modelo desde: {model_uri}\")\n",
    "\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "print(f\"‚úì Modelo cargado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc06e0a",
   "metadata": {},
   "source": [
    "### 1.2 Preparar Datos de Entrada para Batch Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81341a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset local de energ√≠a\n",
    "import os\n",
    "\n",
    "# Ruta al dataset en la misma carpeta\n",
    "local_csv_path = \"owid-energy-data.csv\"\n",
    "\n",
    "# Leer datos de energ√≠a\n",
    "if os.path.exists(local_csv_path):\n",
    "    energy_df = pd.read_csv(local_csv_path)\n",
    "\n",
    "    print(f\"‚úì Dataset cargado: {len(energy_df)} registros\")display(sample_data)\n",
    "\n",
    "else:print(f\"Datos de ejemplo: {len(sample_data)} registros\")\n",
    "\n",
    "    print(\"‚ö†Ô∏è Dataset no encontrado en la carpeta actual\")\n",
    "\n",
    "].dropna().tail(10).reset_index(drop=True)\n",
    "\n",
    "# Preparar datos de ejemplo para predicciones (pa√≠ses recientes)     'fossil_fuel_consumption', 'renewables_consumption']\n",
    "\n",
    "sample_data = energy_df[    ['year', 'population', 'gdp', 'primary_energy_consumption', "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e6cf2",
   "metadata": {},
   "source": [
    "### 1.3 Realizar Predicciones B√°sicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db70b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones con pandas DataFrame\n",
    "predictions = loaded_model.predict(sample_data)\n",
    "\n",
    "# Decodificar predicciones (del Lab 4: 0=Low, 1=Medium, 2=High, 3=Very High)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.classes_ = np.array(['Low', 'Medium', 'High', 'Very High'])\n",
    "predictions_labels = le.inverse_transform(predictions)\n",
    "\n",
    "# Agregar predicciones al DataFrame\n",
    "\n",
    "result_df = sample_data.copy()display(result_df)\n",
    "\n",
    "result_df['prediction_class'] = predictions_labelsprint(pd.Series(predictions_labels).value_counts())\n",
    "\n",
    "result_df['prediction_code'] = predictionsprint(f\"\\nDistribuci√≥n de clases predichas:\")\n",
    "\n",
    "result_df['prediction_timestamp'] = pd.Timestamp.now()print(f\"Total de predicciones: {len(result_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f070c88",
   "metadata": {},
   "source": [
    "### 1.4 Batch Scoring a Gran Escala con Spark UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20b66ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "\n",
    "# Crear Spark DataFrame\n",
    "spark_df = spark.createDataFrame(sample_data)\n",
    "\n",
    "# Definir UDF para predicciones distribuidas (clasificaci√≥n)\n",
    "@pandas_udf(IntegerType())\n",
    "def predict_udf(*cols):\n",
    "    # Reconstruir DataFrame desde columnas\n",
    "    input_df = pd.concat(cols, axis=1)\n",
    "    input_df.columns = sample_data.columns\n",
    "    # Hacer predicci√≥n\n",
    "    return pd.Series(loaded_model.predict(input_df))\n",
    "\n",
    "# Definir UDF para decodificar clases\n",
    "@pandas_udf(StringType())\n",
    "def decode_class_udf(prediction_col):\n",
    "    le = LabelEncoder()\n",
    "    le.classes_ = np.array(['Low', 'Medium', 'High', 'Very High'])\n",
    "    return pd.Series(le.inverse_transform(prediction_col))\n",
    "\n",
    "\n",
    "# Aplicar prediccionesdisplay(predictions_df)\n",
    "\n",
    "predictions_df = spark_df.withColumn(print(\"‚úì Predicciones de clasificaci√≥n generadas\")\n",
    "\n",
    "    \"prediction_code\",\n",
    "\n",
    "    predict_udf(*[col(c) for c in sample_data.columns]))\n",
    "\n",
    ").withColumn(    decode_class_udf(col(\"prediction_code\"))\n",
    "    \"prediction_class\","
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ede9a",
   "metadata": {},
   "source": [
    "### 1.5 Guardar Resultados en Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df0d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir ruta de salida\n",
    "output_path = \"/tmp/predictions/energy_classification/batch_scoring\"\n",
    "\n",
    "# Guardar en Delta Lake\n",
    "predictions_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .save(output_path)\n",
    "\n",
    "print(f\"‚úì Predicciones guardadas en: {output_path}\")\n",
    "\n",
    "# Verificar datos guardados\n",
    "saved_df = spark.read.format(\"delta\").load(output_path)\n",
    "print(f\"Total de registros guardados: {saved_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885837d0",
   "metadata": {},
   "source": [
    "### 1.6 Registrar M√©tricas de Batch Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d80da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Contar predicciones generadas\n",
    "prediction_count = predictions_df.count()\n",
    "\n",
    "# Registrar m√©tricas en MLflow\n",
    "with mlflow.start_run(run_name=\"batch_scoring_metrics\"):\n",
    "    mlflow.log_metric(\"predictions_count\", prediction_count)\n",
    "    mlflow.log_metric(\"execution_timestamp\", datetime.now().timestamp())\n",
    "    mlflow.log_param(\"model_name\", model_name)\n",
    "    mlflow.log_param(\"model_version\", model_version)\n",
    "    mlflow.log_param(\"output_path\", output_path)\n",
    "    \n",
    "print(f\"‚úì M√©tricas registradas en MLflow\")\n",
    "print(f\"  - Predicciones: {prediction_count}\")\n",
    "print(f\"  - Timestamp: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b869fb",
   "metadata": {},
   "source": [
    "## Parte 2: Despliegue de Endpoints en Tiempo Real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc736e6",
   "metadata": {},
   "source": [
    "### 2.1 Crear Endpoint REST con MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d9440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "# Configurar cliente de despliegue\n",
    "client = get_deploy_client(\"databricks\")\n",
    "\n",
    "# Configuraci√≥n del endpoint\n",
    "endpoint_name = \"energy-classifier-endpoint\"\n",
    "\n",
    "endpoint_config = {\n",
    "    \"served_models\": [{\n",
    "        \"model_name\": model_name,\n",
    "        \"model_version\": str(model_version),\n",
    "        \"workload_size\": \"Small\",  # Small, Medium, Large\n",
    "        \"scale_to_zero_enabled\": True  # Escalar a 0 cuando no hay tr√°fico\n",
    "    }]\n",
    "}\n",
    "\n",
    "# Crear endpoint\n",
    "try:\n",
    "    endpoint = client.create_endpoint(\n",
    "        name=endpoint_name,\n",
    "        config=endpoint_config\n",
    "    )\n",
    "    print(f\"‚úì Endpoint creado: {endpoint_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Endpoint ya existe o error: {e}\")\n",
    "    print(\"Continuando con el endpoint existente...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d8295",
   "metadata": {},
   "source": [
    "### 2.2 Verificar Estado del Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1244934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Esperar a que el endpoint est√© listo\n",
    "print(\"Verificando estado del endpoint...\")\n",
    "max_wait = 300  # 5 minutos\n",
    "wait_interval = 10\n",
    "elapsed = 0\n",
    "\n",
    "while elapsed < max_wait:\n",
    "    try:\n",
    "        endpoint_details = client.get_endpoint(endpoint_name)\n",
    "        state = endpoint_details.get('state', {})\n",
    "        \n",
    "        if state.get('ready') == 'READY':\n",
    "            print(f\"\\n‚úì Endpoint listo para recibir tr√°fico\")\n",
    "            print(f\"Estado: {state}\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Esperando... ({elapsed}s/{max_wait}s) - Estado: {state.get('ready', 'UNKNOWN')}\")\n",
    "            time.sleep(wait_interval)\n",
    "            elapsed += wait_interval\n",
    "    except Exception as e:\n",
    "        print(f\"Error al verificar estado: {e}\")\n",
    "        break\n",
    "\n",
    "if elapsed >= max_wait:\n",
    "    print(f\"‚ö†Ô∏è Tiempo de espera agotado. El endpoint puede tardar m√°s en estar listo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb942bb",
   "metadata": {},
   "source": [
    "### 2.3 Consumir Endpoint REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6e5613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Configuraci√≥n\n",
    "workspace_url = spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
    "token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "endpoint_url = f\"https://{workspace_url}/serving-endpoints/{endpoint_name}/invocations\"\n",
    "\n",
    "# Datos de prueba con features de energ√≠a (incluyendo engineered features del Lab 4)\n",
    "test_data = {\n",
    "    \"dataframe_records\": [\n",
    "        {\n",
    "            \"year\": 2022, \"population\": 50000000, \"gdp\": 500000000000, \n",
    "            \"primary_energy_consumption\": 1500, \"fossil_fuel_consumption\": 1200, \n",
    "            \"renewables_consumption\": 300,\n",
    "            \"renewable_ratio\": 300 / 1501,\n",
    "            \"energy_per_capita\": (1500 / 50000000) * 1000000,\n",
    "            \"fossil_ratio\": 1200 / 1501\n",
    "        },\n",
    "        {\n",
    "            \"year\": 2023, \"population\": 51000000, \"gdp\": 520000000000,\n",
    "            \"primary_energy_consumption\": 1520, \"fossil_fuel_consumption\": 1150,\n",
    "            \"renewables_consumption\": 370,\n",
    "            \"renewable_ratio\": 370 / 1521,\n",
    "            \"energy_per_capita\": (1520 / 51000000) * 1000000,\n",
    "            \"fossil_ratio\": 1150 / 1521\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Headers\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Realizar petici√≥n\n",
    "start_time = time.time()\n",
    "response = requests.post(\n",
    "    endpoint_url,\n",
    "    headers=headers,\n",
    "    json=test_data\n",
    ")\n",
    "latency = (time.time() - start_time) * 1000  # ms\n",
    "\n",
    "else:    print(f\"‚úó Error: {response.status_code}\")\n",
    "\n",
    "# Procesar respuesta\n",
    "\n",
    "if response.status_code == 200:    print(f\"\\nLatencia: {latency:.2f} ms\")    print(response.text)\n",
    "\n",
    "    predictions = response.json()\n",
    "\n",
    "    print(\"‚úì Predicciones recibidas:\")    print(json.dumps(predictions, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66688af",
   "metadata": {},
   "source": [
    "## Parte 3: Monitoreo y Logging de Predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f9f2b3",
   "metadata": {},
   "source": [
    "### 3.1 Implementar Logging de Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d86703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "class PredictionLogger:\n",
    "    \"\"\"Logger para predicciones con metadata completa\"\"\"\n",
    "    \n",
    "    def __init__(self, log_table_path, model_name, model_version):\n",
    "        self.log_table_path = log_table_path\n",
    "        self.model_name = model_name\n",
    "        self.model_version = model_version\n",
    "    \n",
    "    def log_prediction(self, input_data, prediction, prediction_label, latency_ms, request_id=None):\n",
    "        \"\"\"Registra predicci√≥n con metadata\"\"\"\n",
    "        if request_id is None:\n",
    "            request_id = str(uuid.uuid4())\n",
    "        \n",
    "        # Preparar log entry\n",
    "        log_entry = {\n",
    "            'request_id': request_id,\n",
    "            'timestamp': datetime.now(),\n",
    "            'model_name': self.model_name,\n",
    "            'model_version': str(self.model_version),\n",
    "            'prediction_code': int(prediction),\n",
    "            'prediction_class': str(prediction_label),\n",
    "            'latency_ms': latency_ms,\n",
    "            **input_data\n",
    "        }\n",
    "        \n",
    "        # Guardar en Delta Lake\n",
    "        log_df = spark.createDataFrame([log_entry])\n",
    "        log_df.write.format(\"delta\").mode(\"append\").save(self.log_table_path)\n",
    "        \n",
    "        return request_id\n",
    "\n",
    "# Crear logger\n",
    "log_path = \"/tmp/ml-monitoring/prediction-logs\"\n",
    "logger = PredictionLogger(log_path, model_name, model_version)\n",
    "\n",
    "print(f\"‚úì Logger configurado en: {log_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a646bd72",
   "metadata": {},
   "source": [
    "### 3.2 Generar Tr√°fico de Prueba con Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b722a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generar tr√°fico sint√©tico con datos de energ√≠a\n",
    "print(\"Generando tr√°fico de prueba...\\n\")\n",
    "\n",
    "# Label encoder para decodificar predicciones\n",
    "le = LabelEncoder()\n",
    "le.classes_ = np.array(['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "num_requests = 20\n",
    "for i in range(num_requests):\n",
    "    # Generar datos de entrada (simulando diferentes pa√≠ses/a√±os)\n",
    "    year = int(np.random.uniform(2015, 2023))\n",
    "    population = int(np.random.uniform(10000000, 100000000))\n",
    "    gdp = int(np.random.uniform(100000000000, 1000000000000))\n",
    "    primary = round(np.random.uniform(500, 3000), 1)\n",
    "    fossil = round(np.random.uniform(400, 2500), 1)\n",
    "    renewables = round(np.random.uniform(50, 800), 1)\n",
    "    \n",
    "    # Calcular features adicionales (del Lab 4)\n",
    "    renewable_ratio = renewables / (primary + 1)\n",
    "    energy_per_capita = (primary / population) * 1000000\n",
    "    fossil_ratio = fossil / (primary + 1)\n",
    "    \n",
    "    test_input = {\n",
    "        'year': year,\n",
    "        'population': population,\n",
    "        'gdp': gdp,\n",
    "        'primary_energy_consumption': primary,\n",
    "        'fossil_fuel_consumption': fossil,\n",
    "\n",
    "        'renewables_consumption': renewables,print(f\"\\n‚úì Tr√°fico de prueba completado: {num_requests} predicciones\")\n",
    "\n",
    "        'renewable_ratio': renewable_ratio,\n",
    "\n",
    "        'energy_per_capita': energy_per_capita,        print(f\"Request {i+1}/{num_requests}: Prediction={prediction_label} (code={prediction}), Latency={latency:.1f}ms\")\n",
    "\n",
    "        'fossil_ratio': fossil_ratio    if i % 5 == 0:\n",
    "\n",
    "    }    \n",
    "\n",
    "        req_id = logger.log_prediction(test_input, prediction, prediction_label, latency)\n",
    "\n",
    "    # Realizar predicci√≥n    # Registrar en log\n",
    "\n",
    "    start = time.time()    \n",
    "\n",
    "    pred_input = pd.DataFrame([test_input])    latency = (time.time() - start) * 1000\n",
    "\n",
    "    prediction = loaded_model.predict(pred_input)[0]    prediction_label = le.inverse_transform([prediction])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e2aa16",
   "metadata": {},
   "source": [
    "### 3.3 Analizar Logs de Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1da5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer logs\n",
    "logs_df = spark.read.format(\"delta\").load(log_path)\n",
    "\n",
    "print(f\"üìä Total de predicciones registradas: {logs_df.count()}\")\n",
    "\n",
    "# Convertir a pandas para an√°lisis\n",
    "logs_pd = logs_df.toPandas()\n",
    "\n",
    "# Estad√≠sticas de latencia\n",
    "print(f\"\\nüìà Estad√≠sticas de Latencia:\")\n",
    "print(f\"  Media: {logs_pd['latency_ms'].mean():.2f} ms\")\n",
    "print(f\"  Mediana (P50): {logs_pd['latency_ms'].quantile(0.5):.2f} ms\")\n",
    "print(f\"  P95: {logs_pd['latency_ms'].quantile(0.95):.2f} ms\")\n",
    "print(f\"  P99: {logs_pd['latency_ms'].quantile(0.99):.2f} ms\")\n",
    "print(f\"  Min: {logs_pd['latency_ms'].min():.2f} ms\")\n",
    "print(f\"  Max: {logs_pd['latency_ms'].max():.2f} ms\")\n",
    "\n",
    "# Estad√≠sticas de predicciones\n",
    "print(f\"\\nüéØ Estad√≠sticas de Predicciones:\")\n",
    "print(f\"\\nDistribuci√≥n de clases predichas:\")\n",
    "print(logs_pd['prediction_class'].value_counts())\n",
    "print(f\"\\nC√≥digos de predicci√≥n:\")\n",
    "print(f\"  Media: {logs_pd['prediction_code'].mean():.3f}\")\n",
    "print(f\"  Std Dev: {logs_pd['prediction_code'].std():.3f}\")\n",
    "print(f\"  Min: {logs_pd['prediction_code'].min()}\")\n",
    "print(f\"  Max: {logs_pd['prediction_code'].max()}\")\n",
    "\n",
    "display(logs_df.orderBy(col(\"timestamp\").desc()).limit(10))\n",
    "# Mostrar muestra de logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9d9eb9",
   "metadata": {},
   "source": [
    "### 3.4 Visualizar M√©tricas de Monitoreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28e49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurar estilo\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Crear dashboard de monitoreo\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Distribuci√≥n de latencia\n",
    "axes[0, 0].hist(logs_pd['latency_ms'], bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].axvline(logs_pd['latency_ms'].mean(), color='red', linestyle='--', label='Media')\n",
    "axes[0, 0].axvline(logs_pd['latency_ms'].quantile(0.95), color='orange', linestyle='--', label='P95')\n",
    "axes[0, 0].set_title('Distribuci√≥n de Latencia', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Latencia (ms)')\n",
    "axes[0, 0].set_ylabel('Frecuencia')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Distribuci√≥n de clases predichas\n",
    "class_counts = logs_pd['prediction_class'].value_counts()\n",
    "axes[0, 1].bar(range(len(class_counts)), class_counts.values, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[0, 1].set_xticks(range(len(class_counts)))\n",
    "axes[0, 1].set_xticklabels(class_counts.index, rotation=45)\n",
    "axes[0, 1].set_title('Distribuci√≥n de Clases Predichas', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Clase de Consumo')\n",
    "axes[0, 1].set_ylabel('Frecuencia')\n",
    "\n",
    "# 3. Predicciones vs Consumo Per C√°pita\n",
    "axes[1, 0].scatter(logs_pd['energy_per_capita'], logs_pd['prediction_code'], alpha=0.6, s=50, c=logs_pd['prediction_code'], cmap='viridis')\n",
    "axes[1, 0].set_title('Predicciones vs Consumo Per C√°pita', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Consumo Per C√°pita')\n",
    "axes[1, 0].set_ylabel('Clase Predicha (0-3)')\n",
    "axes[1, 0].set_yticks([0, 1, 2, 3])\n",
    "axes[1, 0].set_yticklabels(['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "# 4. Ratio Renovable vs Clase Predicha\n",
    "axes[1, 1].scatter(logs_pd['renewable_ratio'], logs_pd['prediction_code'], alpha=0.6, s=50, color='green')\n",
    "axes[1, 1].set_title('Ratio Renovable vs Clase Predicha', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Ratio Renovable')\n",
    "axes[1, 1].set_ylabel('Clase Predicha (0-3)')\n",
    "axes[1, 1].set_yticks([0, 1, 2, 3])\n",
    "axes[1, 1].set_yticklabels(['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/tmp/monitoring_dashboard.png', dpi=100, bbox_inches='tight')\n",
    "display(plt.gcf())\n",
    "\n",
    "# Registrar dashboard en MLflow\n",
    "\n",
    "with mlflow.start_run(run_name=\"monitoring_dashboard\"):print(\"\\n‚úì Dashboard generado y registrado en MLflow\")\n",
    "\n",
    "    mlflow.log_artifact('/tmp/monitoring_dashboard.png')\n",
    "\n",
    "    mlflow.log_metric(\"total_predictions\", len(logs_pd))    mlflow.log_metric(\"p95_latency_ms\", logs_pd['latency_ms'].quantile(0.95))\n",
    "    mlflow.log_metric(\"avg_latency_ms\", logs_pd['latency_ms'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44abcfa2",
   "metadata": {},
   "source": [
    "## Parte 4: Detecci√≥n de Data Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b050662f",
   "metadata": {},
   "source": [
    "### 4.1 Implementar Detecci√≥n de Drift con KS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25918502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def calculate_drift(reference_data, current_data, features, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Detecta drift usando Kolmogorov-Smirnov test\n",
    "    \n",
    "    Args:\n",
    "        reference_data: DataFrame con datos de referencia (training)\n",
    "        current_data: DataFrame con datos actuales (producci√≥n)\n",
    "        features: Lista de features a analizar\n",
    "        threshold: P-value threshold para detectar drift\n",
    "    \n",
    "    Returns:\n",
    "        Dict con resultados de drift por feature\n",
    "    \"\"\"\n",
    "    drift_results = {}\n",
    "    \n",
    "    for feature in features:\n",
    "        # KS test\n",
    "        statistic, p_value = stats.ks_2samp(\n",
    "            reference_data[feature],\n",
    "            current_data[feature]\n",
    "        )\n",
    "        \n",
    "        # Drift detectado si p-value < threshold\n",
    "        drift_results[feature] = {\n",
    "            'statistic': statistic,\n",
    "            'p_value': p_value,\n",
    "            'drift_detected': p_value < threshold,\n",
    "            'severity': 'HIGH' if p_value < 0.01 else 'MEDIUM' if p_value < threshold else 'LOW'\n",
    "        }\n",
    "    \n",
    "    return drift_results\n",
    "\n",
    "print(\"‚úì Funci√≥n de detecci√≥n de drift implementada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60517b2d",
   "metadata": {},
   "source": [
    "### 4.2 Comparar Datos de Training vs Producci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de94c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de referencia (simulados - en producci√≥n vendr√≠an del training set)\n",
    "primary_ref = np.random.normal(1500, 500, 1000)\n",
    "fossil_ref = np.random.normal(1200, 400, 1000)\n",
    "renewables_ref = np.random.normal(300, 150, 1000)\n",
    "population_ref = np.random.normal(50000000, 20000000, 1000)\n",
    "\n",
    "reference_data = pd.DataFrame({\n",
    "    'year': np.random.normal(2018, 2, 1000),\n",
    "    'population': population_ref,\n",
    "    'gdp': np.random.normal(500000000000, 200000000000, 1000),\n",
    "    'primary_energy_consumption': primary_ref,\n",
    "    'fossil_fuel_consumption': fossil_ref,\n",
    "    'renewables_consumption': renewables_ref,\n",
    "    'renewable_ratio': renewables_ref / (primary_ref + 1),\n",
    "    'fossil_ratio': fossil_ref / (primary_ref + 1)\n",
    "})\n",
    "\n",
    "# Datos de producci√≥n\n",
    "production_data = logs_pd[['year', 'population', 'gdp', 'primary_energy_consumption', \n",
    "                            'fossil_fuel_consumption', 'renewables_consumption']]\n",
    "\n",
    "# Detectar drift\n",
    "features = ['year', 'population', 'gdp', 'primary_energy_consumption', \n",
    "            'fossil_fuel_consumption', 'renewables_consumption']\n",
    "drift_results = calculate_drift(reference_data, production_data, features, threshold=0.05)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"üîç An√°lisis de Data Drift:\\n\")\n",
    "print(f\"{'Feature':<20} {'P-Value':<12} {'Statistic':<12} {'Estado':<15} {'Severidad'}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "\n",
    "for feature, result in drift_results.items():\n",
    "drift_count = sum(1 for r in drift_results.values() if r['drift_detected'])print(f\"\\nResumen: {drift_count}/{len(features)} features con drift detectado\")\n",
    "\n",
    "    status = \"‚ö†Ô∏è DRIFT\" if result['drift_detected'] else \"‚úì Sin Drift\"\n",
    "print(f\"\\nResumen: {drift_count}/{len(features)} features con drift detectado\")drift_count = sum(1 for r in drift_results.values() if r['drift_detected'])\n",
    "\n",
    "    print(f\"{feature:<20} {result['p_value']:<12.4f} {result['statistic']:<12.4f} {status:<15} {result['severity']}\")# Contar features con drift\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b397b7",
   "metadata": {},
   "source": [
    "### 4.3 Visualizar Drift por Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8103aba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparaci√≥n de distribuciones\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(features):\n",
    "    # Histogramas superpuestos\n",
    "    axes[idx].hist(reference_data[feature], bins=30, alpha=0.5, label='Training (Reference)', \n",
    "                   edgecolor='black', density=True)\n",
    "    axes[idx].hist(production_data[feature], bins=30, alpha=0.5, label='Production (Current)', \n",
    "                   edgecolor='black', density=True, color='orange')\n",
    "    \n",
    "    # T√≠tulo con informaci√≥n de drift\n",
    "    drift_info = drift_results[feature]\n",
    "    status = \"‚ö†Ô∏è DRIFT DETECTADO\" if drift_info['drift_detected'] else \"‚úì Sin Drift\"\n",
    "    axes[idx].set_title(f'{feature}\\n{status} (p={drift_info[\"p_value\"]:.4f})', \n",
    "                       fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Densidad')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/tmp/drift_analysis.png', dpi=100, bbox_inches='tight')\n",
    "display(plt.gcf())\n",
    "\n",
    "print(\"‚úì Visualizaci√≥n de drift generada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5512ccb1",
   "metadata": {},
   "source": [
    "## Parte 5: Sistema de Alertas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadd77c1",
   "metadata": {},
   "source": [
    "### 5.1 Configurar Sistema de Alertas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b9af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlertSystem:\n",
    "    \"\"\"Sistema de alertas para monitoreo de modelos\"\"\"\n",
    "    \n",
    "    def __init__(self, thresholds):\n",
    "        self.thresholds = thresholds\n",
    "        self.alerts = []\n",
    "    \n",
    "    def check_latency(self, metrics):\n",
    "        \"\"\"Verificar latencia\"\"\"\n",
    "        if metrics.get('p95_latency_ms', 0) > self.thresholds['max_latency_p95_ms']:\n",
    "            self.alerts.append({\n",
    "                'type': 'HIGH_LATENCY',\n",
    "                'severity': 'WARNING',\n",
    "                'message': f\"Latencia P95 ({metrics['p95_latency_ms']:.1f}ms) excede threshold ({self.thresholds['max_latency_p95_ms']}ms)\",\n",
    "                'value': metrics['p95_latency_ms']\n",
    "            })\n",
    "    \n",
    "    def check_drift(self, drift_results):\n",
    "        \"\"\"Verificar data drift\"\"\"\n",
    "        drift_features = [f for f, r in drift_results.items() if r['drift_detected']]\n",
    "        if drift_features:\n",
    "            self.alerts.append({\n",
    "                'type': 'DATA_DRIFT',\n",
    "                'severity': 'WARNING',\n",
    "                'message': f'Drift detectado en features: {\", \".join(drift_features)}',\n",
    "                'features': drift_features\n",
    "            })\n",
    "    \n",
    "    def check_prediction_distribution(self, predictions, expected_mean, tolerance=0.2):\n",
    "        \"\"\"Verificar distribuci√≥n de predicciones\"\"\"\n",
    "        current_mean = predictions.mean()\n",
    "        deviation = abs(current_mean - expected_mean) / expected_mean\n",
    "        \n",
    "        if deviation > tolerance:\n",
    "            self.alerts.append({\n",
    "                'type': 'PREDICTION_DISTRIBUTION_SHIFT',\n",
    "                'severity': 'CRITICAL',\n",
    "                'message': f'Media de predicciones ({current_mean:.3f}) difiere significativamente de la esperada ({expected_mean:.3f})',\n",
    "                'deviation': deviation\n",
    "            })\n",
    "    \n",
    "    def send_alerts(self):\n",
    "        \"\"\"Enviar alertas (simulado)\"\"\"\n",
    "        if not self.alerts:\n",
    "            print(\"‚úì No hay alertas - Sistema operando normalmente\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nüö® {len(self.alerts)} ALERTA(S) DETECTADA(S):\\n\")\n",
    "        for i, alert in enumerate(self.alerts, 1):\n",
    "            print(f\"{i}. [{alert['severity']}] {alert['type']}\")\n",
    "            print(f\"   {alert['message']}\\n\")\n",
    "        \n",
    "        # En producci√≥n, aqu√≠ se integrar√≠a con:\n",
    "        # - Email (SendGrid, SMTP)\n",
    "        # - Slack webhook\n",
    "        # - Microsoft Teams webhook\n",
    "        # - PagerDuty\n",
    "        # - Azure Monitor\n",
    "    \n",
    "    def get_alert_summary(self):\n",
    "        \"\"\"Resumen de alertas\"\"\"\n",
    "        return {\n",
    "            'total': len(self.alerts),\n",
    "            'critical': sum(1 for a in self.alerts if a['severity'] == 'CRITICAL'),\n",
    "            'warning': sum(1 for a in self.alerts if a['severity'] == 'WARNING')\n",
    "        }\n",
    "\n",
    "print(\"‚úì Sistema de alertas implementado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d43b454",
   "metadata": {},
   "source": [
    "### 5.2 Ejecutar Verificaciones y Generar Alertas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ea35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar thresholds\n",
    "thresholds = {\n",
    "    'max_latency_p95_ms': 200,\n",
    "    'min_accuracy': 0.85,\n",
    "    'max_drift_pvalue': 0.05\n",
    "}\n",
    "\n",
    "# Crear sistema de alertas\n",
    "alert_system = AlertSystem(thresholds)\n",
    "\n",
    "# Ejecutar verificaciones\n",
    "metrics = {\n",
    "    'p95_latency_ms': logs_pd['latency_ms'].quantile(0.95),\n",
    "    'avg_latency_ms': logs_pd['latency_ms'].mean()\n",
    "}\n",
    "\n",
    "alert_system.check_latency(metrics)\n",
    "alert_system.check_drift(drift_results)\n",
    "# Para clasificaci√≥n, verificar distribuci√≥n de c√≥digos de clase\n",
    "alert_system.check_prediction_distribution(\n",
    "    logs_pd['prediction_code'], \n",
    "    expected_mean=1.5,  # Media esperada para clases 0-3 (ajustar seg√∫n training)\n",
    "    tolerance=0.5\n",
    ")\n",
    "\n",
    "# Enviar alertas\n",
    "alert_system.send_alerts()\n",
    "\n",
    "# Mostrar resumen\n",
    "summary = alert_system.get_alert_summary()\n",
    "print(f\"\\nüìä Resumen de Alertas:\")\n",
    "print(f\"  Total: {summary['total']}\")\n",
    "print(f\"  Cr√≠ticas: {summary['critical']}\")\n",
    "print(f\"  Advertencias: {summary['warning']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735e9b8c",
   "metadata": {},
   "source": [
    "## Parte 6: Buenas Pr√°cticas - Model Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09659f96",
   "metadata": {},
   "source": [
    "### 6.1 Aplicar Tags al Modelo en Producci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5284309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Tags recomendados para producci√≥n\n",
    "production_tags = {\n",
    "    # Metadata t√©cnica\n",
    "    \"model_type\": \"classification\",\n",
    "    \"framework\": \"sklearn\",\n",
    "    \"algorithm\": \"RandomForest\",\n",
    "    \"n_classes\": \"4\",\n",
    "    \n",
    "    # Informaci√≥n del dataset\n",
    "    \"training_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"training_samples\": \"15000\",\n",
    "    \"features\": \"8\",\n",
    "    \n",
    "    # Deployment info\n",
    "    \"deployed_by\": \"data-science-team\",\n",
    "    \"deployment_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"environment\": \"production\",\n",
    "    \n",
    "    # Monitoring\n",
    "    \"monitoring_enabled\": \"true\",\n",
    "    \"alert_threshold_latency_p95\": \"200\",\n",
    "    \n",
    "    # Business context\n",
    "    \"use_case\": \"energy-consumption-classification\",\n",
    "    \"business_owner\": \"energy-analytics\",\n",
    "    \"classes\": \"Low,Medium,High,Very High\"\n",
    "}\n",
    "\n",
    "# Aplicar tags\n",
    "try:\n",
    "    for key, value in production_tags.items():\n",
    "        client.set_model_version_tag(model_name, model_version, key, value)\n",
    "    print(f\"‚úì {len(production_tags)} tags aplicados al modelo {model_name} v{model_version}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al aplicar tags: {e}\")\n",
    "\n",
    "# Verificar tags\n",
    "try:\n",
    "    model_version_info = client.get_model_version(model_name, model_version)\n",
    "    print(f\"\\nTags actuales:\")\n",
    "\n",
    "    for key, value in model_version_info.tags.items():    print(f\"No se pudieron verificar tags: {e}\")\n",
    "\n",
    "        print(f\"  {key}: {value}\")except Exception as e:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d585ec",
   "metadata": {},
   "source": [
    "## Parte 7: Resumen y Reporte Final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951fcaf5",
   "metadata": {},
   "source": [
    "### 7.1 Generar Reporte de Monitoreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57ddbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar reporte completo\n",
    "report = f\"\"\"\n",
    "{'='*80}\n",
    "REPORTE DE MONITOREO - MODELO EN PRODUCCI√ìN\n",
    "{'='*80}\n",
    "\n",
    "üìã INFORMACI√ìN DEL MODELO\n",
    "  Nombre: {model_name}\n",
    "  Versi√≥n: {model_version}\n",
    "  Endpoint: {endpoint_name}\n",
    "  Fecha de reporte: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "üìä M√âTRICAS DE SERVICIO\n",
    "  Total de predicciones: {len(logs_pd)}\n",
    "  Latencia media: {logs_pd['latency_ms'].mean():.2f} ms\n",
    "  Latencia P95: {logs_pd['latency_ms'].quantile(0.95):.2f} ms\n",
    "  Latencia P99: {logs_pd['latency_ms'].quantile(0.99):.2f} ms\n",
    "\n",
    "üéØ ESTAD√çSTICAS DE PREDICCIONES\n",
    "  Distribuci√≥n de clases:\n",
    "{logs_pd['prediction_class'].value_counts().to_string()}\n",
    "  \n",
    "  C√≥digo promedio: {logs_pd['prediction_code'].mean():.2f}\n",
    "  Desviaci√≥n est√°ndar: {logs_pd['prediction_code'].std():.2f}\n",
    "\n",
    "üîç DETECCI√ìN DE DRIFT\n",
    "  Features analizados: {len(features)}\n",
    "  Features con drift: {sum(1 for r in drift_results.values() if r['drift_detected'])}\n",
    "\"\"\"\n",
    "\n",
    "# Agregar detalles de drift\n",
    "for feature, result in drift_results.items():\n",
    "    if result['drift_detected']:\n",
    "        report += f\"    ‚ö†Ô∏è {feature}: p-value={result['p_value']:.4f}\\n\"\n",
    "\n",
    "report += f\"\"\"\n",
    "üö® ALERTAS\n",
    "  Total de alertas: {summary['total']}\n",
    "  Cr√≠ticas: {summary['critical']}\n",
    "  Advertencias: {summary['warning']}\n",
    "\n",
    "‚úÖ RECOMENDACIONES\n",
    "\"\"\"\n",
    "\n",
    "# Generar recomendaciones din√°micas\n",
    "if summary['total'] == 0:\n",
    "    report += \"  - Sistema operando dentro de par√°metros normales\\n\"\n",
    "    report += \"  - Continuar con monitoreo regular\\n\"\n",
    "else:\n",
    "    if summary['critical'] > 0:\n",
    "        report += \"  - ‚ö†Ô∏è ACCI√ìN INMEDIATA REQUERIDA: Alertas cr√≠ticas detectadas\\n\"\n",
    "    if any(r['drift_detected'] for r in drift_results.values()):\n",
    "        report += \"  - Considerar reentrenamiento del modelo debido a drift\\n\"\n",
    "    if logs_pd['latency_ms'].quantile(0.95) > thresholds['max_latency_p95_ms']:\n",
    "        report += \"  - Optimizar latencia o escalar recursos del endpoint\\n\"\n",
    "\n",
    "report += f\"\"\"\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Guardar reporte\n",
    "report_path = \"/tmp/monitoring_report.txt\"\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "# Registrar en MLflow\n",
    "with mlflow.start_run(run_name=\"monitoring_report\"):\n",
    "    mlflow.log_artifact(report_path)\n",
    "    mlflow.log_artifact('/tmp/monitoring_dashboard.png')\n",
    "    mlflow.log_artifact('/tmp/drift_analysis.png')\n",
    "    \n",
    "    # M√©tricas principales\n",
    "    mlflow.log_metrics({\n",
    "        \"total_predictions\": len(logs_pd),\n",
    "        \"prediction_code_mean\": logs_pd['prediction_code'].mean(),\n",
    "        \"high_class_ratio\": (logs_pd['prediction_class'].isin(['High', 'Very High'])).sum() / len(logs_pd),\n",
    "        \"drift_features_count\": sum(1 for r in drift_results.values() if r['drift_detected']),\n",
    "        \"total_alerts\": summary['total']\n",
    "    })\n",
    "\n",
    "\n",
    "print(\"\\n‚úì Reporte completo generado y registrado en MLflow\")\n",
    "print(\"\\n‚úì Reporte completo generado y registrado en MLflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242af463",
   "metadata": {},
   "source": [
    "## üéâ Laboratorio Completado\n",
    "\n",
    "### Has aprendido a:\n",
    "\n",
    "‚úÖ **Desplegar modelos** con batch scoring y endpoints REST  \n",
    "‚úÖ **Configurar monitoreo** de latencia y m√©tricas de servicio  \n",
    "‚úÖ **Implementar logging** estructurado de predicciones  \n",
    "‚úÖ **Detectar data drift** usando pruebas estad√≠sticas  \n",
    "‚úÖ **Configurar alertas** automatizadas para incidentes  \n",
    "‚úÖ **Aplicar buenas pr√°cticas** de MLOps (tagging, documentaci√≥n)  \n",
    "\n",
    "### Pr√≥ximos Pasos\n",
    "\n",
    "1. **Automatizar monitoreo**: Crear job programado que ejecute este notebook diariamente\n",
    "2. **Integrar alertas**: Conectar con Slack, Teams o email para notificaciones\n",
    "3. **Implementar retraining**: Automatizar reentrenamiento cuando se detecte drift\n",
    "4. **Escalar a producci√≥n**: Mover a entorno productivo con gobernanza completa\n",
    "\n",
    "### Recursos Adicionales\n",
    "\n",
    "- [Databricks Model Serving](https://docs.databricks.com/machine-learning/model-serving/index.html)\n",
    "- [MLflow Deployments](https://mlflow.org/docs/latest/deployment/index.html)\n",
    "- [Model Monitoring Best Practices](https://www.databricks.com/blog/2022/04/19/model-monitoring-best-practices.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300d95e",
   "metadata": {},
   "source": [
    "## Limpieza (Opcional)\n",
    "\n",
    "Ejecuta las siguientes celdas para limpiar recursos creados durante el laboratorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af237411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL: Eliminar endpoint para evitar costos\n",
    "# Descomentar para ejecutar\n",
    "\n",
    "# try:\n",
    "#     client.delete_endpoint(endpoint_name)\n",
    "#     print(f\"‚úì Endpoint {endpoint_name} eliminado\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error al eliminar endpoint: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b561a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL: Limpiar tablas temporales\n",
    "# Descomentar para ejecutar\n",
    "\n",
    "# import shutil\n",
    "# try:\n",
    "#     shutil.rmtree('/dbfs/tmp/predictions')\n",
    "#     shutil.rmtree('/dbfs/tmp/ml-monitoring')\n",
    "#     print(\"‚úì Tablas temporales eliminadas\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error al limpiar: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
