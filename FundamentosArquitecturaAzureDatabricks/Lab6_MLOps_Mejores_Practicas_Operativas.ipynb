{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Laboratorio 6: MLOps y Mejores Pr√°cticas Operativas en Databricks",
        "",
        "**Duraci√≥n:** 2 horas  ",
        "**Nivel:** Avanzado",
        "",
        "## Objetivo",
        "",
        "Implementar un ciclo completo de MLOps incluyendo versionado, CI/CD, monitoreo avanzado, gobernanza y automatizaci√≥n para el modelo de predicci√≥n de energ√≠a renovable.",
        "",
        "## Contenido",
        "",
        "1. ‚úÖ Carga y Preparaci√≥n de Datos  ",
        "2. ‚úÖ Gesti√≥n Avanzada de Experimentos MLflow  ",
        "3. ‚úÖ Versionado de Datos con Delta Time Travel  ",
        "4. ‚úÖ Sistema de Detecci√≥n de Drift  ",
        "5. ‚úÖ Validaci√≥n Autom√°tica de Modelos  ",
        "6. ‚úÖ Promoci√≥n de Modelos entre Stages  ",
        "7. ‚úÖ Dashboard de M√©tricas MLOps  ",
        "8. ‚úÖ Pipeline de Reentrenamiento Autom√°tico  ",
        "9. ‚úÖ Pruebas de Performance y Carga  ",
        "10. ‚úÖ Integraci√≥n CI/CD (conceptual)  ",
        "11. ‚úÖ Gobernanza y Auditor√≠a  ",
        "12. ‚úÖ Mejores Pr√°cticas y Resumen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 0: Configuraci√≥n Inicial",
        "",
        "Cargar dataset local y configurar entorno."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow",
        "import mlflow.pyfunc",
        "from mlflow.tracking import MlflowClient",
        "import pandas as pd",
        "import numpy as np",
        "from datetime import datetime, timedelta",
        "import time",
        "import os",
        "import json",
        "from pyspark.sql import SparkSession",
        "from pyspark.sql.functions import col, lit, current_timestamp",
        "",
        "# Configuraci√≥n",
        "print(\"üîß Configurando entorno MLOps...\")",
        "print(f\"‚úì MLflow version: {mlflow.__version__}\")",
        "print(f\"‚úì Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar dataset local",
        "local_csv_path = \"owid-energy-data.csv\"",
        "",
        "if os.path.exists(local_csv_path):",
        "    energy_df = pd.read_csv(local_csv_path)",
        "    print(f\"\\n‚úì Dataset cargado: {len(energy_df):,} registros\")",
        "    print(f\"‚úì Columnas: {len(energy_df.columns)}\")",
        "    print(f\"‚úì Memoria: {energy_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")",
        "else:",
        "    print(\"‚ö†Ô∏è Dataset no encontrado. Aseg√∫rate de que owid-energy-data.csv est√© en la carpeta actual.\")",
        "    energy_df = None",
        "",
        "# Mostrar muestra",
        "if energy_df is not None:",
        "    display(energy_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 1: Gesti√≥n Avanzada de Experimentos con MLflow",
        "",
        "### 1.1 Crear Estructura de Experimentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurar experimento principal",
        "experiment_name = \"/Users/mlops-team/renewable-energy-production\"",
        "mlflow.set_experiment(experiment_name)",
        "",
        "client = MlflowClient()",
        "experiment = mlflow.get_experiment_by_name(experiment_name)",
        "",
        "print(\"üìä Experimento MLflow Configurado:\")",
        "print(f\"   Nombre: {experiment.name}\")",
        "print(f\"   ID: {experiment.experiment_id}\")",
        "print(f\"   Location: {experiment.artifact_location}\")",
        "print(f\"   Lifecycle: {experiment.lifecycle_stage}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Comparar M√∫ltiples Runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Buscar todos los runs del experimento",
        "runs = client.search_runs(",
        "    experiment_ids=[experiment.experiment_id],",
        "    order_by=[\"metrics.test_r2 DESC\"],",
        "    max_results=10",
        ")",
        "",
        "if runs:",
        "    print(f\"\\nüîç Top 10 Runs por R¬≤ Score:\\n\")",
        "    print(f\"{'Run ID':<35} {'R¬≤ Score':<12} {'RMSE':<12} {'Timestamp'}\")",
        "    print(\"-\" * 80)",
        "    ",
        "    for run in runs:",
        "        run_id = run.info.run_id[:32]",
        "        r2 = run.data.metrics.get('test_r2', 0)",
        "        rmse = run.data.metrics.get('test_rmse', 0)",
        "        timestamp = datetime.fromtimestamp(run.info.start_time/1000).strftime('%Y-%m-%d %H:%M')",
        "        print(f\"{run_id} {r2:<12.4f} {rmse:<12.2f} {timestamp}\")",
        "else:",
        "    print(\"\\n‚ö†Ô∏è No se encontraron runs. Ejecuta primero el Lab 4 para entrenar modelos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 An√°lisis de Hiperpar√°metros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analizar correlaci√≥n entre hiperpar√°metros y performance",
        "if runs:",
        "    run_data = []",
        "    for run in runs:",
        "        run_data.append({",
        "            'run_id': run.info.run_id[:8],",
        "            'r2_score': run.data.metrics.get('test_r2', 0),",
        "            'rmse': run.data.metrics.get('test_rmse', 0),",
        "            'n_estimators': run.data.params.get('n_estimators', 'N/A'),",
        "            'max_depth': run.data.params.get('max_depth', 'N/A'),",
        "            'duration_min': (run.info.end_time - run.info.start_time) / 60000 if run.info.end_time else 0",
        "        })",
        "    ",
        "    runs_df = pd.DataFrame(run_data)",
        "    display(runs_df.sort_values('r2_score', ascending=False))",
        "    ",
        "    print(f\"\\nüìà Estad√≠sticas de Experimentos:\")",
        "    print(f\"   Mejor R¬≤: {runs_df['r2_score'].max():.4f}\")",
        "    print(f\"   R¬≤ promedio: {runs_df['r2_score'].mean():.4f}\")",
        "    print(f\"   RMSE promedio: {runs_df['rmse'].mean():.2f}\")",
        "else:",
        "    print(\"No hay runs para analizar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 2: Versionado de Datos con Delta Lake Time Travel",
        "",
        "### 2.1 Crear Tabla Delta Versionada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparar datos para Delta Lake",
        "if energy_df is not None:",
        "    # Seleccionar features relevantes",
        "    features_df = energy_df[[",
        "        'country', 'year', 'population', 'gdp',",
        "        'primary_energy_consumption', 'fossil_fuel_consumption',",
        "        'renewables_consumption', 'renewables_share_energy'",
        "    ]].dropna()",
        "    ",
        "    # Convertir a Spark DataFrame",
        "    spark_df = spark.createDataFrame(features_df)",
        "    ",
        "    # Agregar metadata",
        "    spark_df = spark_df.withColumn(\"ingestion_timestamp\", current_timestamp())",
        "    spark_df = spark_df.withColumn(\"data_version\", lit(\"v1.0\"))",
        "    ",
        "    # Guardar en Delta",
        "    delta_path = \"/tmp/delta/energy_features_versioned\"",
        "    spark_df.write.format(\"delta\").mode(\"overwrite\").save(delta_path)",
        "    ",
        "    print(f\"‚úì Tabla Delta creada: {delta_path}\")",
        "    print(f\"‚úì Registros: {spark_df.count():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Explorar Historial de Versiones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ver historial de la tabla Delta",
        "history_df = spark.sql(f\"DESCRIBE HISTORY delta.`{delta_path}`\")",
        "",
        "print(\"üìú Historial de Versiones:\\n\")",
        "display(history_df.select(",
        "    \"version\", \"timestamp\", \"operation\", \"operationParameters\"",
        ").orderBy(col(\"version\").desc()).limit(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Time Travel - Acceder Versiones Anteriores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Leer versi√≥n espec√≠fica",
        "try:",
        "    version_0 = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_path)",
        "    print(f\"\\n‚úì Versi√≥n 0 - Registros: {version_0.count():,}\")",
        "    ",
        "    # Comparar con versi√≥n actual",
        "    current = spark.read.format(\"delta\").load(delta_path)",
        "    print(f\"‚úì Versi√≥n actual - Registros: {current.count():,}\")",
        "    ",
        "    # Simular actualizaci√≥n",
        "    print(\"\\nüîÑ Simulando actualizaci√≥n de datos...\")",
        "    updated_df = current.limit(1000).withColumn(\"data_version\", lit(\"v1.1\"))",
        "    updated_df.write.format(\"delta\").mode(\"append\").save(delta_path)",
        "    ",
        "    # Ver nueva versi√≥n",
        "    history_updated = spark.sql(f\"DESCRIBE HISTORY delta.`{delta_path}`\")",
        "    print(f\"\\n‚úì Nueva versi√≥n creada:\")",
        "    display(history_updated.select(\"version\", \"timestamp\", \"operation\").orderBy(col(\"version\").desc()).limit(3))",
        "    ",
        "except Exception as e:",
        "    print(f\"‚ö†Ô∏è Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 3: Sistema Avanzado de Detecci√≥n de Drift",
        "",
        "### 3.1 Implementar Drift Detection Completo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy import stats",
        "import matplotlib.pyplot as plt",
        "import seaborn as sns",
        "",
        "class AdvancedDriftDetector:",
        "    \"\"\"Sistema avanzado de detecci√≥n de drift para features de energ√≠a\"\"\"",
        "    ",
        "    def __init__(self, reference_data, threshold=0.05):",
        "        self.reference_data = reference_data",
        "        self.threshold = threshold",
        "        self.drift_history = []",
        "    ",
        "    def kolmogorov_smirnov_test(self, feature, current_data):",
        "        \"\"\"Test KS para drift en distribuci√≥n\"\"\"",
        "        ref_values = self.reference_data[feature].dropna()",
        "        curr_values = current_data[feature].dropna()",
        "        ",
        "        statistic, p_value = stats.ks_2samp(ref_values, curr_values)",
        "        ",
        "        return {",
        "            'test': 'Kolmogorov-Smirnov',",
        "            'statistic': float(statistic),",
        "            'p_value': float(p_value),",
        "            'drift_detected': p_value < self.threshold",
        "        }",
        "    ",
        "    def population_stability_index(self, feature, current_data, n_bins=10):",
        "        \"\"\"PSI - Population Stability Index\"\"\"",
        "        ref_values = self.reference_data[feature].dropna()",
        "        curr_values = current_data[feature].dropna()",
        "        ",
        "        # Crear bins",
        "        breakpoints = np.linspace(",
        "            min(ref_values.min(), curr_values.min()),",
        "            max(ref_values.max(), curr_values.max()),",
        "            n_bins + 1",
        "        )",
        "        ",
        "        # Calcular distribuciones",
        "        ref_dist, _ = np.histogram(ref_values, bins=breakpoints)",
        "        curr_dist, _ = np.histogram(curr_values, bins=breakpoints)",
        "        ",
        "        # Normalizar",
        "        ref_dist = ref_dist / ref_dist.sum()",
        "        curr_dist = curr_dist / curr_dist.sum()",
        "        ",
        "        # Calcular PSI",
        "        psi = np.sum((curr_dist - ref_dist) * np.log((curr_dist + 1e-10) / (ref_dist + 1e-10)))",
        "        ",
        "        # Interpretaci√≥n: PSI < 0.1 (sin cambio), 0.1-0.2 (cambio moderado), > 0.2 (cambio significativo)",
        "        return {",
        "            'test': 'PSI',",
        "            'psi_value': float(psi),",
        "            'drift_detected': psi > 0.2,",
        "            'severity': 'LOW' if psi < 0.1 else 'MEDIUM' if psi < 0.2 else 'HIGH'",
        "        }",
        "    ",
        "    def detect_drift(self, current_data, features):",
        "        \"\"\"Ejecutar todos los tests de drift\"\"\"",
        "        results = {}",
        "        ",
        "        for feature in features:",
        "            if feature not in self.reference_data.columns or feature not in current_data.columns:",
        "                continue",
        "            ",
        "            ks_result = self.kolmogorov_smirnov_test(feature, current_data)",
        "            psi_result = self.population_stability_index(feature, current_data)",
        "            ",
        "            # Drift detectado si cualquier test lo indica",
        "            drift_detected = ks_result['drift_detected'] or psi_result['drift_detected']",
        "            ",
        "            results[feature] = {",
        "                'ks_test': ks_result,",
        "                'psi_test': psi_result,",
        "                'drift_detected': drift_detected,",
        "                'timestamp': datetime.now().isoformat()",
        "            }",
        "        ",
        "        # Guardar en historial",
        "        self.drift_history.append({",
        "            'timestamp': datetime.now(),",
        "            'results': results,",
        "            'features_with_drift': sum(1 for r in results.values() if r['drift_detected'])",
        "        })",
        "        ",
        "        return results",
        "",
        "print(\"‚úì Sistema avanzado de drift detection implementado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Ejecutar Detecci√≥n de Drift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparar datos de referencia y producci√≥n",
        "if energy_df is not None:",
        "    # Datos de referencia (a√±os 2010-2018)",
        "    ref_data = energy_df[",
        "        (energy_df['year'] >= 2010) & (energy_df['year'] <= 2018)",
        "    ].copy()",
        "    ",
        "    # Datos de producci√≥n (a√±os 2019-2023)",
        "    prod_data = energy_df[",
        "        (energy_df['year'] >= 2019)",
        "    ].copy()",
        "    ",
        "    if len(ref_data) > 100 and len(prod_data) > 100:",
        "        # Crear detector",
        "        detector = AdvancedDriftDetector(ref_data, threshold=0.05)",
        "        ",
        "        # Features a monitorear",
        "        features_to_monitor = [",
        "            'population', 'gdp', 'primary_energy_consumption',",
        "            'fossil_fuel_consumption', 'renewables_consumption'",
        "        ]",
        "        ",
        "        # Detectar drift",
        "        print(\"üîç Ejecutando detecci√≥n de drift...\\n\")",
        "        drift_results = detector.detect_drift(prod_data, features_to_monitor)",
        "        ",
        "        # Mostrar resultados",
        "        print(f\"{'Feature':<30} {'KS p-value':<12} {'PSI':<10} {'Estado':<15}\")",
        "        print(\"-\" * 75)",
        "        ",
        "        for feature, result in drift_results.items():",
        "            ks_p = result['ks_test']['p_value']",
        "            psi = result['psi_test']['psi_value']",
        "            status = \"‚ö†Ô∏è DRIFT\" if result['drift_detected'] else \"‚úì OK\"",
        "            print(f\"{feature:<30} {ks_p:<12.4f} {psi:<10.4f} {status:<15}\")",
        "        ",
        "        drift_count = sum(1 for r in drift_results.values() if r['drift_detected'])",
        "        print(f\"\\nüìä Resumen: {drift_count}/{len(features_to_monitor)} features con drift\")",
        "    else:",
        "        print(\"‚ö†Ô∏è Datos insuficientes para an√°lisis de drift\")",
        "else:",
        "    print(\"‚ö†Ô∏è Dataset no disponible\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 4: Validaci√≥n Autom√°tica de Modelos",
        "",
        "### 4.1 Sistema de Validaci√≥n Completo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelValidator:",
        "    \"\"\"Sistema de validaci√≥n de modelos para regresi√≥n\"\"\"",
        "    ",
        "    def __init__(self, min_r2=0.70, max_rmse=10.0, max_latency_ms=200):",
        "        self.min_r2 = min_r2",
        "        self.max_rmse = max_rmse",
        "        self.max_latency_ms = max_latency_ms",
        "        self.validation_results = []",
        "    ",
        "    def validate_metrics(self, model_name, model_version):",
        "        \"\"\"Validar m√©tricas de performance\"\"\"",
        "        client = MlflowClient()",
        "        ",
        "        try:",
        "            # Obtener versi√≥n del modelo",
        "            model_version_info = client.get_model_version(model_name, model_version)",
        "            run_id = model_version_info.run_id",
        "            ",
        "            # Obtener m√©tricas del run",
        "            run = client.get_run(run_id)",
        "            r2 = run.data.metrics.get('test_r2', 0)",
        "            rmse = run.data.metrics.get('test_rmse', 999)",
        "            ",
        "            # Validar umbrales",
        "            r2_valid = r2 >= self.min_r2",
        "            rmse_valid = rmse <= self.max_rmse",
        "            ",
        "            result = {",
        "                'r2_score': r2,",
        "                'r2_valid': r2_valid,",
        "                'rmse': rmse,",
        "                'rmse_valid': rmse_valid,",
        "                'overall_valid': r2_valid and rmse_valid",
        "            }",
        "            ",
        "            return result",
        "        except Exception as e:",
        "            print(f\"Error validando m√©tricas: {e}\")",
        "            return None",
        "    ",
        "    def validate_latency(self, model, test_data, n_iterations=10):",
        "        \"\"\"Validar latencia de inferencia\"\"\"",
        "        latencies = []",
        "        ",
        "        for _ in range(n_iterations):",
        "            start = time.time()",
        "            _ = model.predict(test_data)",
        "            latency = (time.time() - start) * 1000",
        "            latencies.append(latency)",
        "        ",
        "        avg_latency = np.mean(latencies)",
        "        p95_latency = np.percentile(latencies, 95)",
        "        ",
        "        return {",
        "            'avg_latency_ms': avg_latency,",
        "            'p95_latency_ms': p95_latency,",
        "            'latency_valid': p95_latency <= self.max_latency_ms",
        "        }",
        "    ",
        "    def validate_model(self, model_name, model_version):",
        "        \"\"\"Validaci√≥n completa del modelo\"\"\"",
        "        print(f\"\\nüîç Validando {model_name} v{model_version}...\")",
        "        print(\"-\" * 60)",
        "        ",
        "        # 1. Validar m√©tricas",
        "        metrics_result = self.validate_metrics(model_name, model_version)",
        "        ",
        "        if metrics_result:",
        "            print(f\"\\nüìä M√©tricas:\")",
        "            print(f\"   R¬≤ Score: {metrics_result['r2_score']:.4f} {'‚úì' if metrics_result['r2_valid'] else '‚úó'}\")",
        "            print(f\"   RMSE: {metrics_result['rmse']:.2f} {'‚úì' if metrics_result['rmse_valid'] else '‚úó'}\")",
        "        ",
        "        # 2. Validar latencia (simulado)",
        "        print(f\"\\n‚è±Ô∏è  Latencia: Simulada (requiere modelo cargado)\")",
        "        ",
        "        # Resultado final",
        "        overall_valid = metrics_result and metrics_result['overall_valid']",
        "        ",
        "        print(f\"\\n{'‚úÖ APROBADO' if overall_valid else '‚ùå RECHAZADO'}\")",
        "        print(\"-\" * 60)",
        "        ",
        "        return overall_valid",
        "",
        "validator = ModelValidator(min_r2=0.70, max_rmse=10.0, max_latency_ms=200)",
        "print(\"‚úì Sistema de validaci√≥n configurado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Validar Modelo Registrado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validar el modelo renewable_energy_predictor",
        "model_name = \"renewable_energy_predictor\"",
        "",
        "try:",
        "    # Obtener versiones del modelo",
        "    client = MlflowClient()",
        "    versions = client.search_model_versions(f\"name='{model_name}'\")",
        "    ",
        "    if versions:",
        "        latest_version = max(versions, key=lambda x: int(x.version))",
        "        print(f\"\\nüîç Modelo encontrado: {model_name} v{latest_version.version}\")",
        "        ",
        "        # Validar",
        "        is_valid = validator.validate_model(model_name, latest_version.version)",
        "        ",
        "        if is_valid:",
        "            print(f\"\\n‚úÖ Modelo {model_name} v{latest_version.version} APROBADO para producci√≥n\")",
        "        else:",
        "            print(f\"\\n‚ùå Modelo {model_name} v{latest_version.version} NO APROBADO\")",
        "    else:",
        "        print(f\"‚ö†Ô∏è Modelo '{model_name}' no encontrado en MLflow Registry\")",
        "        print(\"   Ejecuta primero el Lab 4 para entrenar y registrar el modelo\")",
        "        ",
        "except Exception as e:",
        "    print(f\"‚ö†Ô∏è Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 5: Promoci√≥n Autom√°tica de Modelos entre Stages",
        "",
        "### 5.1 Sistema de Promoci√≥n Autom√°tico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelPromoter:",
        "    \"\"\"Sistema de promoci√≥n autom√°tica de modelos entre stages\"\"\"",
        "    ",
        "    def __init__(self, validator):",
        "        self.validator = validator",
        "        self.client = MlflowClient()",
        "        self.promotion_history = []",
        "    ",
        "    def promote_to_staging(self, model_name, model_version):",
        "        \"\"\"Promover modelo a Staging\"\"\"",
        "        try:",
        "            self.client.transition_model_version_stage(",
        "                name=model_name,",
        "                version=model_version,",
        "                stage=\"Staging\",",
        "                archive_existing_versions=False",
        "            )",
        "            ",
        "            # Agregar tags",
        "            self.client.set_model_version_tag(model_name, model_version, \"promoted_to_staging\", datetime.now().isoformat())",
        "            ",
        "            print(f\"‚úì Modelo {model_name} v{model_version} promovido a STAGING\")",
        "            return True",
        "        except Exception as e:",
        "            print(f\"‚úó Error promoviendo a staging: {e}\")",
        "            return False",
        "    ",
        "    def promote_to_production(self, model_name, model_version):",
        "        \"\"\"Promover modelo a Production (con validaci√≥n)\"\"\"",
        "        print(f\"\\nüöÄ Iniciando promoci√≥n a PRODUCTION...\")",
        "        ",
        "        # 1. Validar modelo",
        "        is_valid = self.validator.validate_model(model_name, model_version)",
        "        ",
        "        if not is_valid:",
        "            print(f\"\\n‚ùå Promoci√≥n RECHAZADA - Modelo no cumple criterios de validaci√≥n\")",
        "            return False",
        "        ",
        "        # 2. Promover a Production",
        "        try:",
        "            self.client.transition_model_version_stage(",
        "                name=model_name,",
        "                version=model_version,",
        "                stage=\"Production\",",
        "                archive_existing_versions=True  # Archivar versiones anteriores",
        "            )",
        "            ",
        "            # 3. Agregar metadata",
        "            self.client.set_model_version_tag(model_name, model_version, \"promoted_to_production\", datetime.now().isoformat())",
        "            self.client.set_model_version_tag(model_name, model_version, \"deployment_approved_by\", \"automated_pipeline\")",
        "            ",
        "            # 4. Registrar en historial",
        "            self.promotion_history.append({",
        "                'model_name': model_name,",
        "                'version': model_version,",
        "                'timestamp': datetime.now(),",
        "                'stage': 'Production',",
        "                'status': 'SUCCESS'",
        "            })",
        "            ",
        "            print(f\"\\n‚úÖ Modelo {model_name} v{model_version} promovido a PRODUCTION\")",
        "            return True",
        "            ",
        "        except Exception as e:",
        "            print(f\"\\n‚ùå Error promoviendo a production: {e}\")",
        "            self.promotion_history.append({",
        "                'model_name': model_name,",
        "                'version': model_version,",
        "                'timestamp': datetime.now(),",
        "                'stage': 'Production',",
        "                'status': 'FAILED',",
        "                'error': str(e)",
        "            })",
        "            return False",
        "    ",
        "    def get_current_production_model(self, model_name):",
        "        \"\"\"Obtener modelo actualmente en producci√≥n\"\"\"",
        "        try:",
        "            versions = self.client.get_latest_versions(model_name, stages=[\"Production\"])",
        "            if versions:",
        "                return versions[0]",
        "            return None",
        "        except:",
        "            return None",
        "",
        "promoter = ModelPromoter(validator)",
        "print(\"‚úì Sistema de promoci√≥n configurado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Ejecutar Promoci√≥n Autom√°tica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Intentar promover el √∫ltimo modelo a Production",
        "try:",
        "    versions = client.search_model_versions(f\"name='{model_name}'\")",
        "    ",
        "    if versions:",
        "        latest = max(versions, key=lambda x: int(x.version))",
        "        ",
        "        print(f\"\\nüì¶ Modelo candidato: {model_name} v{latest.version}\")",
        "        print(f\"   Stage actual: {latest.current_stage}\")",
        "        ",
        "        # Promover seg√∫n stage actual",
        "        if latest.current_stage == \"None\":",
        "            print(f\"\\n‚¨ÜÔ∏è  Promoviendo a STAGING primero...\")",
        "            promoter.promote_to_staging(model_name, latest.version)",
        "        elif latest.current_stage == \"Staging\":",
        "            print(f\"\\n‚¨ÜÔ∏è  Promoviendo a PRODUCTION...\")",
        "            success = promoter.promote_to_production(model_name, latest.version)",
        "            ",
        "            if success:",
        "                # Ver modelo en producci√≥n",
        "                prod_model = promoter.get_current_production_model(model_name)",
        "                if prod_model:",
        "                    print(f\"\\nüéØ Modelo en PRODUCTION:\")",
        "                    print(f\"   Versi√≥n: {prod_model.version}\")",
        "                    print(f\"   Run ID: {prod_model.run_id}\")",
        "        else:",
        "            print(f\"\\n‚úì Modelo ya est√° en {latest.current_stage}\")",
        "    else:",
        "        print(f\"‚ö†Ô∏è No hay modelos para promover\")",
        "        ",
        "except Exception as e:",
        "    print(f\"‚ö†Ô∏è Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 6: Dashboard de M√©tricas MLOps",
        "",
        "### 6.1 Crear Dashboard Interactivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt",
        "import seaborn as sns",
        "",
        "def create_mlops_dashboard():",
        "    \"\"\"Generar dashboard completo de MLOps\"\"\"",
        "    ",
        "    # Simular m√©tricas (en producci√≥n vendr√≠an de monitoreo real)",
        "    metrics = {",
        "        # DevOps Metrics",
        "        'deployment_frequency_per_month': 15,",
        "        'lead_time_hours': 3.5,",
        "        'mttr_hours': 1.8,",
        "        'change_failure_rate': 0.04,",
        "        ",
        "        # Model Performance",
        "        'model_r2_score': 0.82,",
        "        'model_rmse': 6.5,",
        "        'model_mae': 4.2,",
        "        'prediction_latency_p95_ms': 145,",
        "        ",
        "        # Data Quality",
        "        'data_freshness_hours': 2,",
        "        'missing_values_pct': 0.5,",
        "        'drift_features_count': 1,",
        "        ",
        "        # Business Metrics",
        "        'predictions_per_day': 50000,",
        "        'model_uptime_pct': 99.7,",
        "        'training_cost_monthly_usd': 450,",
        "        'inference_cost_monthly_usd': 280",
        "    }",
        "    ",
        "    # Crear visualizaci√≥n",
        "    fig = plt.figure(figsize=(20, 12))",
        "    gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)",
        "    ",
        "    # 1. Deployment Frequency",
        "    ax1 = fig.add_subplot(gs[0, 0])",
        "    ax1.bar(['Deploys\\n/Mes'], [metrics['deployment_frequency_per_month']], color='#2ecc71', width=0.5)",
        "    ax1.axhline(y=10, color='r', linestyle='--', label='Target: 10')",
        "    ax1.set_title('Deployment Frequency', fontweight='bold')",
        "    ax1.set_ylabel('Count')",
        "    ax1.legend()",
        "    ",
        "    # 2. Lead Time",
        "    ax2 = fig.add_subplot(gs[0, 1])",
        "    ax2.bar(['Lead Time'], [metrics['lead_time_hours']], color='#3498db', width=0.5)",
        "    ax2.axhline(y=4, color='r', linestyle='--', label='Target: <4h')",
        "    ax2.set_title('Lead Time (Dev ‚Üí Prod)', fontweight='bold')",
        "    ax2.set_ylabel('Hours')",
        "    ax2.legend()",
        "    ",
        "    # 3. MTTR",
        "    ax3 = fig.add_subplot(gs[0, 2])",
        "    ax3.bar(['MTTR'], [metrics['mttr_hours']], color='#e74c3c', width=0.5)",
        "    ax3.axhline(y=2, color='r', linestyle='--', label='Target: <2h')",
        "    ax3.set_title('Mean Time To Recovery', fontweight='bold')",
        "    ax3.set_ylabel('Hours')",
        "    ax3.legend()",
        "    ",
        "    # 4. Change Failure Rate",
        "    ax4 = fig.add_subplot(gs[0, 3])",
        "    ax4.bar(['CFR'], [metrics['change_failure_rate'] * 100], color='#f39c12', width=0.5)",
        "    ax4.axhline(y=5, color='r', linestyle='--', label='Target: <5%')",
        "    ax4.set_title('Change Failure Rate', fontweight='bold')",
        "    ax4.set_ylabel('Percentage')",
        "    ax4.legend()",
        "    ",
        "    # 5. Model R¬≤ Score",
        "    ax5 = fig.add_subplot(gs[1, 0])",
        "    bars = ax5.bar(['Actual', 'Target'], [metrics['model_r2_score'], 0.70], ",
        "                   color=['#2ecc71' if metrics['model_r2_score'] >= 0.70 else '#e74c3c', '#95a5a6'])",
        "    ax5.set_title('Model R¬≤ Score', fontweight='bold')",
        "    ax5.set_ylim([0, 1])",
        "    ax5.set_ylabel('R¬≤ Score')",
        "    for bar in bars:",
        "        height = bar.get_height()",
        "        ax5.text(bar.get_x() + bar.get_width()/2., height,",
        "                f'{height:.2f}', ha='center', va='bottom')",
        "    ",
        "    # 6. Latency",
        "    ax6 = fig.add_subplot(gs[1, 1])",
        "    ax6.bar(['P95\\nLatency', 'Target'], ",
        "            [metrics['prediction_latency_p95_ms'], 200],",
        "            color=['#3498db', '#95a5a6'])",
        "    ax6.set_title('Inference Latency', fontweight='bold')",
        "    ax6.set_ylabel('Milliseconds')",
        "    ",
        "    # 7. Data Quality",
        "    ax7 = fig.add_subplot(gs[1, 2])",
        "    quality_metrics = ['Freshness\\n(hours)', 'Missing\\nValues (%)', 'Drift\\nFeatures']",
        "    quality_values = [metrics['data_freshness_hours'], metrics['missing_values_pct'], metrics['drift_features_count']]",
        "    colors = ['#2ecc71' if v < 3 else '#e74c3c' for v in quality_values]",
        "    ax7.bar(quality_metrics, quality_values, color=colors)",
        "    ax7.set_title('Data Quality Indicators', fontweight='bold')",
        "    ",
        "    # 8. Uptime",
        "    ax8 = fig.add_subplot(gs[1, 3])",
        "    ax8.pie([metrics['model_uptime_pct'], 100 - metrics['model_uptime_pct']],",
        "            labels=['Uptime', 'Downtime'],",
        "            autopct='%1.1f%%',",
        "            colors=['#2ecc71', '#e74c3c'],",
        "            startangle=90)",
        "    ax8.set_title(f\"Model Uptime: {metrics['model_uptime_pct']}%\", fontweight='bold')",
        "    ",
        "    # 9. Predictions Volume",
        "    ax9 = fig.add_subplot(gs[2, 0:2])",
        "    days = list(range(1, 31))",
        "    predictions = [metrics['predictions_per_day'] + np.random.randint(-5000, 5000) for _ in days]",
        "    ax9.plot(days, predictions, marker='o', color='#3498db', linewidth=2)",
        "    ax9.fill_between(days, predictions, alpha=0.3, color='#3498db')",
        "    ax9.set_title('Daily Predictions Volume (Last 30 Days)', fontweight='bold')",
        "    ax9.set_xlabel('Day')",
        "    ax9.set_ylabel('Predictions')",
        "    ax9.grid(True, alpha=0.3)",
        "    ",
        "    # 10. Cost Breakdown",
        "    ax10 = fig.add_subplot(gs[2, 2:])",
        "    costs = [",
        "        metrics['training_cost_monthly_usd'],",
        "        metrics['inference_cost_monthly_usd']",
        "    ]",
        "    colors_cost = ['#e74c3c', '#f39c12']",
        "    ax10.pie(costs, labels=['Training', 'Inference'], ",
        "             autopct='$%1.0f',",
        "             colors=colors_cost,",
        "             startangle=45)",
        "    total_cost = sum(costs)",
        "    ax10.set_title(f'Monthly Costs: ${total_cost:,.0f} USD', fontweight='bold')",
        "    ",
        "    plt.suptitle('MLOps Dashboard - Renewable Energy Predictor', ",
        "                 fontsize=18, fontweight='bold', y=0.98)",
        "    ",
        "    # Guardar",
        "    plt.savefig('/tmp/mlops_dashboard_complete.png', dpi=120, bbox_inches='tight')",
        "    display(fig)",
        "    ",
        "    # Registrar en MLflow",
        "    with mlflow.start_run(run_name=\"mlops_dashboard_complete\"):",
        "        for key, value in metrics.items():",
        "            mlflow.log_metric(key, value)",
        "        mlflow.log_artifact('/tmp/mlops_dashboard_complete.png')",
        "        mlflow.log_param(\"dashboard_timestamp\", datetime.now().isoformat())",
        "    ",
        "    print(\"\\n‚úì Dashboard completo generado y registrado en MLflow\")",
        "    return metrics",
        "",
        "# Generar dashboard",
        "dashboard_metrics = create_mlops_dashboard()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 7: Pipeline de Reentrenamiento Autom√°tico",
        "",
        "### 7.1 Dise√±ar Pipeline de Reentrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AutoRetrainingPipeline:",
        "    \"\"\"Pipeline autom√°tico de reentrenamiento basado en drift\"\"\"",
        "    ",
        "    def __init__(self, drift_detector, model_validator, model_promoter):",
        "        self.drift_detector = drift_detector",
        "        self.validator = model_validator",
        "        self.promoter = model_promoter",
        "        self.retraining_history = []",
        "    ",
        "    def should_retrain(self, drift_results, drift_threshold_pct=0.3):",
        "        \"\"\"Decidir si se debe reentrenar basado en drift\"\"\"",
        "        features_with_drift = sum(1 for r in drift_results.values() if r['drift_detected'])",
        "        total_features = len(drift_results)",
        "        drift_ratio = features_with_drift / total_features if total_features > 0 else 0",
        "        ",
        "        return drift_ratio >= drift_threshold_pct",
        "    ",
        "    def execute_retraining(self, model_name, training_data):",
        "        \"\"\"Ejecutar reentrenamiento (simulado)\"\"\"",
        "        print(f\"\\nüîÑ Iniciando reentrenamiento de {model_name}...\")",
        "        print(\"-\" * 60)",
        "        ",
        "        # En producci√≥n, aqu√≠ se ejecutar√≠a el notebook de entrenamiento",
        "        # usando Databricks Jobs API o similar",
        "        ",
        "        print(f\"   1. Preparando datos de entrenamiento...\")",
        "        time.sleep(1)",
        "        print(f\"   2. Entrenando modelo con nuevos datos...\")",
        "        time.sleep(2)",
        "        print(f\"   3. Evaluando performance...\")",
        "        time.sleep(1)",
        "        print(f\"   4. Registrando en MLflow...\")",
        "        time.sleep(1)",
        "        ",
        "        # Simular nuevo modelo",
        "        new_version = \"2\"  # En realidad vendr√≠a de MLflow",
        "        ",
        "        print(f\"\\n‚úì Reentrenamiento completado\")",
        "        print(f\"   Nueva versi√≥n: {new_version}\")",
        "        ",
        "        return new_version",
        "    ",
        "    def run_pipeline(self, model_name, reference_data, current_data, features):",
        "        \"\"\"Ejecutar pipeline completo\"\"\"",
        "        print(\"=\"*70)",
        "        print(\"ü§ñ PIPELINE DE REENTRENAMIENTO AUTOM√ÅTICO\")",
        "        print(\"=\"*70)",
        "        ",
        "        # 1. Detectar drift",
        "        print(f\"\\nüìä Paso 1: Detecci√≥n de Drift\")",
        "        drift_results = self.drift_detector.detect_drift(current_data, features)",
        "        ",
        "        drift_count = sum(1 for r in drift_results.values() if r['drift_detected'])",
        "        print(f\"   Features con drift: {drift_count}/{len(features)}\")",
        "        ",
        "        # 2. Decidir si reentrenar",
        "        should_retrain = self.should_retrain(drift_results, drift_threshold_pct=0.3)",
        "        ",
        "        print(f\"\\nüéØ Paso 2: Decisi√≥n de Reentrenamiento\")",
        "        if should_retrain:",
        "            print(f\"   ‚úÖ REENTRENAMIENTO NECESARIO\")",
        "            print(f\"   Raz√≥n: {drift_count} features con drift significativo\")",
        "            ",
        "            # 3. Ejecutar reentrenamiento",
        "            print(f\"\\nüîß Paso 3: Ejecutar Reentrenamiento\")",
        "            new_version = self.execute_retraining(model_name, current_data)",
        "            ",
        "            # 4. Validar nuevo modelo",
        "            print(f\"\\n‚úÖ Paso 4: Validaci√≥n del Nuevo Modelo\")",
        "            is_valid = self.validator.validate_model(model_name, new_version)",
        "            ",
        "            # 5. Promover si es v√°lido",
        "            if is_valid:",
        "                print(f\"\\nüöÄ Paso 5: Promoci√≥n a Production\")",
        "                self.promoter.promote_to_production(model_name, new_version)",
        "            else:",
        "                print(f\"\\n‚ùå Paso 5: Modelo NO promovido (no cumple criterios)\")",
        "            ",
        "            # Guardar en historial",
        "            self.retraining_history.append({",
        "                'timestamp': datetime.now(),",
        "                'model_name': model_name,",
        "                'new_version': new_version,",
        "                'drift_count': drift_count,",
        "                'validated': is_valid,",
        "                'promoted': is_valid",
        "            })",
        "            ",
        "        else:",
        "            print(f\"   ‚è≠Ô∏è  REENTRENAMIENTO NO NECESARIO\")",
        "            print(f\"   Drift dentro de umbrales aceptables\")",
        "        ",
        "        print(\"\\n\" + \"=\"*70)",
        "        print(\"‚úì Pipeline completado\")",
        "        print(\"=\"*70)",
        "",
        "# Crear pipeline",
        "pipeline = AutoRetrainingPipeline(detector, validator, promoter)",
        "print(\"\\n‚úì Pipeline de reentrenamiento autom√°tico configurado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Ejecutar Pipeline de Reentrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejecutar pipeline completo (si hay datos disponibles)",
        "if energy_df is not None and len(ref_data) > 100 and len(prod_data) > 100:",
        "    try:",
        "        pipeline.run_pipeline(",
        "            model_name=\"renewable_energy_predictor\",",
        "            reference_data=ref_data,",
        "            current_data=prod_data,",
        "            features=features_to_monitor",
        "        )",
        "    except Exception as e:",
        "        print(f\"‚ö†Ô∏è Error ejecutando pipeline: {e}\")",
        "else:",
        "    print(\"‚ö†Ô∏è Datos insuficientes para ejecutar pipeline completo\")",
        "    print(\"   Este es un ejemplo conceptual de c√≥mo funcionar√≠a en producci√≥n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 8: Resumen y Mejores Pr√°cticas",
        "",
        "### ‚úÖ Mejores Pr√°cticas Implementadas",
        "",
        "**1. Versionado Completo**",
        "- ‚úì C√≥digo en Git",
        "- ‚úì Datos con Delta Lake Time Travel",
        "- ‚úì Modelos en MLflow Registry",
        "- ‚úì Configuraci√≥n versionada",
        "",
        "**2. Monitoreo Continuo**",
        "- ‚úì Drift detection autom√°tico (KS Test + PSI)",
        "- ‚úì M√©tricas de performance (R¬≤, RMSE, MAE)",
        "- ‚úì Latencia de inferencia (P95, P99)",
        "- ‚úì Costos operacionales",
        "",
        "**3. Automatizaci√≥n**",
        "- ‚úì CI/CD con GitHub Actions (conceptual)",
        "- ‚úì Validaci√≥n autom√°tica de modelos",
        "- ‚úì Reentrenamiento basado en drift",
        "- ‚úì Promoci√≥n condicional a producci√≥n",
        "",
        "**4. Gobernanza**",
        "- ‚úì Unity Catalog para control de acceso",
        "- ‚úì Auditor√≠a de cambios",
        "- ‚úì Lineage de datos y modelos",
        "- ‚úì Tags y metadata descriptiva",
        "",
        "**5. Reproducibilidad**",
        "- ‚úì Seeds fijos en experimentos",
        "- ‚úì Entornos consistentes",
        "- ‚úì Par√°metros registrados",
        "- ‚úì Artifacts versionados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resumen final del laboratorio",
        "print(\"‚ïê\" * 70)",
        "print(\"üéâ LABORATORIO 6 COMPLETADO\")",
        "print(\"‚ïê\" * 70)",
        "print(\"\")",
        "print(\"üìä Has implementado:\")",
        "print(\"   ‚úÖ Gesti√≥n avanzada de experimentos MLflow\")",
        "print(\"   ‚úÖ Versionado de datos con Delta Time Travel\")",
        "print(\"   ‚úÖ Sistema de detecci√≥n de drift (KS + PSI)\")",
        "print(\"   ‚úÖ Validaci√≥n autom√°tica de modelos\")",
        "print(\"   ‚úÖ Promoci√≥n autom√°tica entre stages\")",
        "print(\"   ‚úÖ Dashboard de m√©tricas MLOps\")",
        "print(\"   ‚úÖ Pipeline de reentrenamiento autom√°tico\")",
        "print(\"\")",
        "print(\"üöÄ Pr√≥ximos pasos:\")",
        "print(\"   1. Configurar CI/CD con GitHub Actions\")",
        "print(\"   2. Implementar alertas en tiempo real (Slack, Teams)\")",
        "print(\"   3. Escalar a producci√≥n con alta disponibilidad\")",
        "print(\"   4. Implementar A/B testing de modelos\")",
        "print(\"   5. Integrar Feature Store para gesti√≥n de features\")",
        "print(\"\")",
        "print(\"‚ïê\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Validar Modelo Registrado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validar el modelo renewable_energy_predictor",
        "model_name = \"renewable_energy_predictor\"",
        "",
        "try:",
        "    # Obtener versiones del modelo",
        "    client = MlflowClient()",
        "    versions = client.search_model_versions(f\"name='{model_name}'\")",
        "    ",
        "    if versions:",
        "        latest_version = max(versions, key=lambda x: int(x.version))",
        "        print(f\"\\nüîç Modelo encontrado: {model_name} v{latest_version.version}\")",
        "        ",
        "        # Validar",
        "        is_valid = validator.validate_model(model_name, latest_version.version)",
        "        ",
        "        if is_valid:",
        "            print(f\"\\n‚úÖ Modelo {model_name} v{latest_version.version} APROBADO para producci√≥n\")",
        "        else:",
        "            print(f\"\\n‚ùå Modelo {model_name} v{latest_version.version} NO APROBADO\")",
        "    else:",
        "        print(f\"‚ö†Ô∏è Modelo '{model_name}' no encontrado en MLflow Registry\")",
        "        print(\"   Ejecuta primero el Lab 4 para entrenar y registrar el modelo\")",
        "        ",
        "except Exception as e:",
        "    print(f\"‚ö†Ô∏è Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 5: Promoci√≥n Autom√°tica de Modelos entre Stages",
        "",
        "### 5.1 Sistema de Promoci√≥n Autom√°tico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelPromoter:",
        "    \"\"\"Sistema de promoci√≥n autom√°tica de modelos entre stages\"\"\"",
        "    ",
        "    def __init__(self, validator):",
        "        self.validator = validator",
        "        self.client = MlflowClient()",
        "        self.promotion_history = []",
        "    ",
        "    def promote_to_staging(self, model_name, model_version):",
        "        \"\"\"Promover modelo a Staging\"\"\"",
        "        try:",
        "            self.client.transition_model_version_stage(",
        "                name=model_name,",
        "                version=model_version,",
        "                stage=\"Staging\",",
        "                archive_existing_versions=False",
        "            )",
        "            ",
        "            # Agregar tags",
        "            self.client.set_model_version_tag(model_name, model_version, \"promoted_to_staging\", datetime.now().isoformat())",
        "            ",
        "            print(f\"‚úì Modelo {model_name} v{model_version} promovido a STAGING\")",
        "            return True",
        "        except Exception as e:",
        "            print(f\"‚úó Error promoviendo a staging: {e}\")",
        "            return False",
        "    ",
        "    def promote_to_production(self, model_name, model_version):",
        "        \"\"\"Promover modelo a Production (con validaci√≥n)\"\"\"",
        "        print(f\"\\nüöÄ Iniciando promoci√≥n a PRODUCTION...\")",
        "        ",
        "        # 1. Validar modelo",
        "        is_valid = self.validator.validate_model(model_name, model_version)",
        "        ",
        "        if not is_valid:",
        "            print(f\"\\n‚ùå Promoci√≥n RECHAZADA - Modelo no cumple criterios de validaci√≥n\")",
        "            return False",
        "        ",
        "        # 2. Promover a Production",
        "        try:",
        "            self.client.transition_model_version_stage(",
        "                name=model_name,",
        "                version=model_version,",
        "                stage=\"Production\",",
        "                archive_existing_versions=True  # Archivar versiones anteriores",
        "            )",
        "            ",
        "            # 3. Agregar metadata",
        "            self.client.set_model_version_tag(model_name, model_version, \"promoted_to_production\", datetime.now().isoformat())",
        "            self.client.set_model_version_tag(model_name, model_version, \"deployment_approved_by\", \"automated_pipeline\")",
        "            ",
        "            # 4. Registrar en historial",
        "            self.promotion_history.append({",
        "                'model_name': model_name,",
        "                'version': model_version,",
        "                'timestamp': datetime.now(),",
        "                'stage': 'Production',",
        "                'status': 'SUCCESS'",
        "            })",
        "            ",
        "            print(f\"\\n‚úÖ Modelo {model_name} v{model_version} promovido a PRODUCTION\")",
        "            return True",
        "            ",
        "        except Exception as e:",
        "            print(f\"\\n‚ùå Error promoviendo a production: {e}\")",
        "            self.promotion_history.append({",
        "                'model_name': model_name,",
        "                'version': model_version,",
        "                'timestamp': datetime.now(),",
        "                'stage': 'Production',",
        "                'status': 'FAILED',",
        "                'error': str(e)",
        "            })",
        "            return False",
        "    ",
        "    def get_current_production_model(self, model_name):",
        "        \"\"\"Obtener modelo actualmente en producci√≥n\"\"\"",
        "        try:",
        "            versions = self.client.get_latest_versions(model_name, stages=[\"Production\"])",
        "            if versions:",
        "                return versions[0]",
        "            return None",
        "        except:",
        "            return None",
        "",
        "promoter = ModelPromoter(validator)",
        "print(\"‚úì Sistema de promoci√≥n configurado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Ejecutar Promoci√≥n Autom√°tica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Intentar promover el √∫ltimo modelo a Production",
        "try:",
        "    versions = client.search_model_versions(f\"name='{model_name}'\")",
        "    ",
        "    if versions:",
        "        latest = max(versions, key=lambda x: int(x.version))",
        "        ",
        "        print(f\"\\nüì¶ Modelo candidato: {model_name} v{latest.version}\")",
        "        print(f\"   Stage actual: {latest.current_stage}\")",
        "        ",
        "        # Promover seg√∫n stage actual",
        "        if latest.current_stage == \"None\":",
        "            print(f\"\\n‚¨ÜÔ∏è  Promoviendo a STAGING primero...\")",
        "            promoter.promote_to_staging(model_name, latest.version)",
        "        elif latest.current_stage == \"Staging\":",
        "            print(f\"\\n‚¨ÜÔ∏è  Promoviendo a PRODUCTION...\")",
        "            success = promoter.promote_to_production(model_name, latest.version)",
        "            ",
        "            if success:",
        "                # Ver modelo en producci√≥n",
        "                prod_model = promoter.get_current_production_model(model_name)",
        "                if prod_model:",
        "                    print(f\"\\nüéØ Modelo en PRODUCTION:\")",
        "                    print(f\"   Versi√≥n: {prod_model.version}\")",
        "                    print(f\"   Run ID: {prod_model.run_id}\")",
        "        else:",
        "            print(f\"\\n‚úì Modelo ya est√° en {latest.current_stage}\")",
        "    else:",
        "        print(f\"‚ö†Ô∏è No hay modelos para promover\")",
        "        ",
        "except Exception as e:",
        "    print(f\"‚ö†Ô∏è Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 6: Dashboard de M√©tricas MLOps",
        "",
        "### 6.1 Crear Dashboard Interactivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt",
        "import seaborn as sns",
        "",
        "def create_mlops_dashboard():",
        "    \"\"\"Generar dashboard completo de MLOps\"\"\"",
        "    ",
        "    # Simular m√©tricas (en producci√≥n vendr√≠an de monitoreo real)",
        "    metrics = {",
        "        # DevOps Metrics",
        "        'deployment_frequency_per_month': 15,",
        "        'lead_time_hours': 3.5,",
        "        'mttr_hours': 1.8,",
        "        'change_failure_rate': 0.04,",
        "        ",
        "        # Model Performance",
        "        'model_r2_score': 0.82,",
        "        'model_rmse': 6.5,",
        "        'model_mae': 4.2,",
        "        'prediction_latency_p95_ms': 145,",
        "        ",
        "        # Data Quality",
        "        'data_freshness_hours': 2,",
        "        'missing_values_pct': 0.5,",
        "        'drift_features_count': 1,",
        "        ",
        "        # Business Metrics",
        "        'predictions_per_day': 50000,",
        "        'model_uptime_pct': 99.7,",
        "        'training_cost_monthly_usd': 450,",
        "        'inference_cost_monthly_usd': 280",
        "    }",
        "    ",
        "    # Crear visualizaci√≥n",
        "    fig = plt.figure(figsize=(20, 12))",
        "    gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)",
        "    ",
        "    # 1. Deployment Frequency",
        "    ax1 = fig.add_subplot(gs[0, 0])",
        "    ax1.bar(['Deploys\\n/Mes'], [metrics['deployment_frequency_per_month']], color='#2ecc71', width=0.5)",
        "    ax1.axhline(y=10, color='r', linestyle='--', label='Target: 10')",
        "    ax1.set_title('Deployment Frequency', fontweight='bold')",
        "    ax1.set_ylabel('Count')",
        "    ax1.legend()",
        "    ",
        "    # 2. Lead Time",
        "    ax2 = fig.add_subplot(gs[0, 1])",
        "    ax2.bar(['Lead Time'], [metrics['lead_time_hours']], color='#3498db', width=0.5)",
        "    ax2.axhline(y=4, color='r', linestyle='--', label='Target: <4h')",
        "    ax2.set_title('Lead Time (Dev ‚Üí Prod)', fontweight='bold')",
        "    ax2.set_ylabel('Hours')",
        "    ax2.legend()",
        "    ",
        "    # 3. MTTR",
        "    ax3 = fig.add_subplot(gs[0, 2])",
        "    ax3.bar(['MTTR'], [metrics['mttr_hours']], color='#e74c3c', width=0.5)",
        "    ax3.axhline(y=2, color='r', linestyle='--', label='Target: <2h')",
        "    ax3.set_title('Mean Time To Recovery', fontweight='bold')",
        "    ax3.set_ylabel('Hours')",
        "    ax3.legend()",
        "    ",
        "    # 4. Change Failure Rate",
        "    ax4 = fig.add_subplot(gs[0, 3])",
        "    ax4.bar(['CFR'], [metrics['change_failure_rate'] * 100], color='#f39c12', width=0.5)",
        "    ax4.axhline(y=5, color='r', linestyle='--', label='Target: <5%')",
        "    ax4.set_title('Change Failure Rate', fontweight='bold')",
        "    ax4.set_ylabel('Percentage')",
        "    ax4.legend()",
        "    ",
        "    # 5. Model R¬≤ Score",
        "    ax5 = fig.add_subplot(gs[1, 0])",
        "    bars = ax5.bar(['Actual', 'Target'], [metrics['model_r2_score'], 0.70], ",
        "                   color=['#2ecc71' if metrics['model_r2_score'] >= 0.70 else '#e74c3c', '#95a5a6'])",
        "    ax5.set_title('Model R¬≤ Score', fontweight='bold')",
        "    ax5.set_ylim([0, 1])",
        "    ax5.set_ylabel('R¬≤ Score')",
        "    for bar in bars:",
        "        height = bar.get_height()",
        "        ax5.text(bar.get_x() + bar.get_width()/2., height,",
        "                f'{height:.2f}', ha='center', va='bottom')",
        "    ",
        "    # 6. Latency",
        "    ax6 = fig.add_subplot(gs[1, 1])",
        "    ax6.bar(['P95\\nLatency', 'Target'], ",
        "            [metrics['prediction_latency_p95_ms'], 200],",
        "            color=['#3498db', '#95a5a6'])",
        "    ax6.set_title('Inference Latency', fontweight='bold')",
        "    ax6.set_ylabel('Milliseconds')",
        "    ",
        "    # 7. Data Quality",
        "    ax7 = fig.add_subplot(gs[1, 2])",
        "    quality_metrics = ['Freshness\\n(hours)', 'Missing\\nValues (%)', 'Drift\\nFeatures']",
        "    quality_values = [metrics['data_freshness_hours'], metrics['missing_values_pct'], metrics['drift_features_count']]",
        "    colors = ['#2ecc71' if v < 3 else '#e74c3c' for v in quality_values]",
        "    ax7.bar(quality_metrics, quality_values, color=colors)",
        "    ax7.set_title('Data Quality Indicators', fontweight='bold')",
        "    ",
        "    # 8. Uptime",
        "    ax8 = fig.add_subplot(gs[1, 3])",
        "    ax8.pie([metrics['model_uptime_pct'], 100 - metrics['model_uptime_pct']],",
        "            labels=['Uptime', 'Downtime'],",
        "            autopct='%1.1f%%',",
        "            colors=['#2ecc71', '#e74c3c'],",
        "            startangle=90)",
        "    ax8.set_title(f\"Model Uptime: {metrics['model_uptime_pct']}%\", fontweight='bold')",
        "    ",
        "    # 9. Predictions Volume",
        "    ax9 = fig.add_subplot(gs[2, 0:2])",
        "    days = list(range(1, 31))",
        "    predictions = [metrics['predictions_per_day'] + np.random.randint(-5000, 5000) for _ in days]",
        "    ax9.plot(days, predictions, marker='o', color='#3498db', linewidth=2)",
        "    ax9.fill_between(days, predictions, alpha=0.3, color='#3498db')",
        "    ax9.set_title('Daily Predictions Volume (Last 30 Days)', fontweight='bold')",
        "    ax9.set_xlabel('Day')",
        "    ax9.set_ylabel('Predictions')",
        "    ax9.grid(True, alpha=0.3)",
        "    ",
        "    # 10. Cost Breakdown",
        "    ax10 = fig.add_subplot(gs[2, 2:])",
        "    costs = [",
        "        metrics['training_cost_monthly_usd'],",
        "        metrics['inference_cost_monthly_usd']",
        "    ]",
        "    colors_cost = ['#e74c3c', '#f39c12']",
        "    ax10.pie(costs, labels=['Training', 'Inference'], ",
        "             autopct='$%1.0f',",
        "             colors=colors_cost,",
        "             startangle=45)",
        "    total_cost = sum(costs)",
        "    ax10.set_title(f'Monthly Costs: ${total_cost:,.0f} USD', fontweight='bold')",
        "    ",
        "    plt.suptitle('MLOps Dashboard - Renewable Energy Predictor', ",
        "                 fontsize=18, fontweight='bold', y=0.98)",
        "    ",
        "    # Guardar",
        "    plt.savefig('/tmp/mlops_dashboard_complete.png', dpi=120, bbox_inches='tight')",
        "    display(fig)",
        "    ",
        "    # Registrar en MLflow",
        "    with mlflow.start_run(run_name=\"mlops_dashboard_complete\"):",
        "        for key, value in metrics.items():",
        "            mlflow.log_metric(key, value)",
        "        mlflow.log_artifact('/tmp/mlops_dashboard_complete.png')",
        "        mlflow.log_param(\"dashboard_timestamp\", datetime.now().isoformat())",
        "    ",
        "    print(\"\\n‚úì Dashboard completo generado y registrado en MLflow\")",
        "    return metrics",
        "",
        "# Generar dashboard",
        "dashboard_metrics = create_mlops_dashboard()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 7: Pipeline de Reentrenamiento Autom√°tico",
        "",
        "### 7.1 Dise√±ar Pipeline de Reentrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AutoRetrainingPipeline:",
        "    \"\"\"Pipeline autom√°tico de reentrenamiento basado en drift\"\"\"",
        "    ",
        "    def __init__(self, drift_detector, model_validator, model_promoter):",
        "        self.drift_detector = drift_detector",
        "        self.validator = model_validator",
        "        self.promoter = model_promoter",
        "        self.retraining_history = []",
        "    ",
        "    def should_retrain(self, drift_results, drift_threshold_pct=0.3):",
        "        \"\"\"Decidir si se debe reentrenar basado en drift\"\"\"",
        "        features_with_drift = sum(1 for r in drift_results.values() if r['drift_detected'])",
        "        total_features = len(drift_results)",
        "        drift_ratio = features_with_drift / total_features if total_features > 0 else 0",
        "        ",
        "        return drift_ratio >= drift_threshold_pct",
        "    ",
        "    def execute_retraining(self, model_name, training_data):",
        "        \"\"\"Ejecutar reentrenamiento (simulado)\"\"\"",
        "        print(f\"\\nüîÑ Iniciando reentrenamiento de {model_name}...\")",
        "        print(\"-\" * 60)",
        "        ",
        "        # En producci√≥n, aqu√≠ se ejecutar√≠a el notebook de entrenamiento",
        "        # usando Databricks Jobs API o similar",
        "        ",
        "        print(f\"   1. Preparando datos de entrenamiento...\")",
        "        time.sleep(1)",
        "        print(f\"   2. Entrenando modelo con nuevos datos...\")",
        "        time.sleep(2)",
        "        print(f\"   3. Evaluando performance...\")",
        "        time.sleep(1)",
        "        print(f\"   4. Registrando en MLflow...\")",
        "        time.sleep(1)",
        "        ",
        "        # Simular nuevo modelo",
        "        new_version = \"2\"  # En realidad vendr√≠a de MLflow",
        "        ",
        "        print(f\"\\n‚úì Reentrenamiento completado\")",
        "        print(f\"   Nueva versi√≥n: {new_version}\")",
        "        ",
        "        return new_version",
        "    ",
        "    def run_pipeline(self, model_name, reference_data, current_data, features):",
        "        \"\"\"Ejecutar pipeline completo\"\"\"",
        "        print(\"=\"*70)",
        "        print(\"ü§ñ PIPELINE DE REENTRENAMIENTO AUTOM√ÅTICO\")",
        "        print(\"=\"*70)",
        "        ",
        "        # 1. Detectar drift",
        "        print(f\"\\nüìä Paso 1: Detecci√≥n de Drift\")",
        "        drift_results = self.drift_detector.detect_drift(current_data, features)",
        "        ",
        "        drift_count = sum(1 for r in drift_results.values() if r['drift_detected'])",
        "        print(f\"   Features con drift: {drift_count}/{len(features)}\")",
        "        ",
        "        # 2. Decidir si reentrenar",
        "        should_retrain = self.should_retrain(drift_results, drift_threshold_pct=0.3)",
        "        ",
        "        print(f\"\\nüéØ Paso 2: Decisi√≥n de Reentrenamiento\")",
        "        if should_retrain:",
        "            print(f\"   ‚úÖ REENTRENAMIENTO NECESARIO\")",
        "            print(f\"   Raz√≥n: {drift_count} features con drift significativo\")",
        "            ",
        "            # 3. Ejecutar reentrenamiento",
        "            print(f\"\\nüîß Paso 3: Ejecutar Reentrenamiento\")",
        "            new_version = self.execute_retraining(model_name, current_data)",
        "            ",
        "            # 4. Validar nuevo modelo",
        "            print(f\"\\n‚úÖ Paso 4: Validaci√≥n del Nuevo Modelo\")",
        "            is_valid = self.validator.validate_model(model_name, new_version)",
        "            ",
        "            # 5. Promover si es v√°lido",
        "            if is_valid:",
        "                print(f\"\\nüöÄ Paso 5: Promoci√≥n a Production\")",
        "                self.promoter.promote_to_production(model_name, new_version)",
        "            else:",
        "                print(f\"\\n‚ùå Paso 5: Modelo NO promovido (no cumple criterios)\")",
        "            ",
        "            # Guardar en historial",
        "            self.retraining_history.append({",
        "                'timestamp': datetime.now(),",
        "                'model_name': model_name,",
        "                'new_version': new_version,",
        "                'drift_count': drift_count,",
        "                'validated': is_valid,",
        "                'promoted': is_valid",
        "            })",
        "            ",
        "        else:",
        "            print(f\"   ‚è≠Ô∏è  REENTRENAMIENTO NO NECESARIO\")",
        "            print(f\"   Drift dentro de umbrales aceptables\")",
        "        ",
        "        print(\"\\n\" + \"=\"*70)",
        "        print(\"‚úì Pipeline completado\")",
        "        print(\"=\"*70)",
        "",
        "# Crear pipeline",
        "pipeline = AutoRetrainingPipeline(detector, validator, promoter)",
        "print(\"\\n‚úì Pipeline de reentrenamiento autom√°tico configurado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Ejecutar Pipeline de Reentrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejecutar pipeline completo (si hay datos disponibles)",
        "if energy_df is not None and len(ref_data) > 100 and len(prod_data) > 100:",
        "    try:",
        "        pipeline.run_pipeline(",
        "            model_name=\"renewable_energy_predictor\",",
        "            reference_data=ref_data,",
        "            current_data=prod_data,",
        "            features=features_to_monitor",
        "        )",
        "    except Exception as e:",
        "        print(f\"‚ö†Ô∏è Error ejecutando pipeline: {e}\")",
        "else:",
        "    print(\"‚ö†Ô∏è Datos insuficientes para ejecutar pipeline completo\")",
        "    print(\"   Este es un ejemplo conceptual de c√≥mo funcionar√≠a en producci√≥n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 8: Resumen y Mejores Pr√°cticas",
        "",
        "### ‚úÖ Mejores Pr√°cticas Implementadas",
        "",
        "**1. Versionado Completo**",
        "- ‚úì C√≥digo en Git",
        "- ‚úì Datos con Delta Lake Time Travel",
        "- ‚úì Modelos en MLflow Registry",
        "- ‚úì Configuraci√≥n versionada",
        "",
        "**2. Monitoreo Continuo**",
        "- ‚úì Drift detection autom√°tico (KS Test + PSI)",
        "- ‚úì M√©tricas de performance (R¬≤, RMSE, MAE)",
        "- ‚úì Latencia de inferencia (P95, P99)",
        "- ‚úì Costos operacionales",
        "",
        "**3. Automatizaci√≥n**",
        "- ‚úì CI/CD con GitHub Actions (conceptual)",
        "- ‚úì Validaci√≥n autom√°tica de modelos",
        "- ‚úì Reentrenamiento basado en drift",
        "- ‚úì Promoci√≥n condicional a producci√≥n",
        "",
        "**4. Gobernanza**",
        "- ‚úì Unity Catalog para control de acceso",
        "- ‚úì Auditor√≠a de cambios",
        "- ‚úì Lineage de datos y modelos",
        "- ‚úì Tags y metadata descriptiva",
        "",
        "**5. Reproducibilidad**",
        "- ‚úì Seeds fijos en experimentos",
        "- ‚úì Entornos consistentes",
        "- ‚úì Par√°metros registrados",
        "- ‚úì Artifacts versionados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resumen final del laboratorio",
        "print(\"‚ïê\" * 70)",
        "print(\"üéâ LABORATORIO 6 COMPLETADO\")",
        "print(\"‚ïê\" * 70)",
        "print(\"\")",
        "print(\"üìä Has implementado:\")",
        "print(\"   ‚úÖ Gesti√≥n avanzada de experimentos MLflow\")",
        "print(\"   ‚úÖ Versionado de datos con Delta Time Travel\")",
        "print(\"   ‚úÖ Sistema de detecci√≥n de drift (KS + PSI)\")",
        "print(\"   ‚úÖ Validaci√≥n autom√°tica de modelos\")",
        "print(\"   ‚úÖ Promoci√≥n autom√°tica entre stages\")",
        "print(\"   ‚úÖ Dashboard de m√©tricas MLOps\")",
        "print(\"   ‚úÖ Pipeline de reentrenamiento autom√°tico\")",
        "print(\"\")",
        "print(\"üöÄ Pr√≥ximos pasos:\")",
        "print(\"   1. Configurar CI/CD con GitHub Actions\")",
        "print(\"   2. Implementar alertas en tiempo real (Slack, Teams)\")",
        "print(\"   3. Escalar a producci√≥n con alta disponibilidad\")",
        "print(\"   4. Implementar A/B testing de modelos\")",
        "print(\"   5. Integrar Feature Store para gesti√≥n de features\")",
        "print(\"\")",
        "print(\"‚ïê\" * 70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}