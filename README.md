# Azure Databricks Workshop

![Azure Databricks](https://img.shields.io/badge/Azure-Databricks-FF6C37?style=for-the-badge&logo=databricks&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Spark](https://img.shields.io/badge/Apache_Spark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)
![MLflow](https://img.shields.io/badge/MLflow-0194E2?style=for-the-badge&logo=mlflow&logoColor=white)

## ğŸ“‹ DescripciÃ³n

Workshop completo de **Azure Databricks** diseÃ±ado para llevar a los participantes desde los fundamentos hasta tÃ©cnicas avanzadas de Big Data, Machine Learning y MLOps. Este repositorio contiene laboratorios prÃ¡cticos, notebooks interactivos y documentaciÃ³n detallada para dominar el ecosistema de Databricks en Azure.

## ğŸ¯ Objetivos del Workshop

- Dominar los fundamentos de Azure Databricks y Apache Spark
- Implementar pipelines de datos escalables y eficientes
- Aplicar feature engineering y anÃ¡lisis exploratorio de datos
- Entrenar, registrar y desplegar modelos de Machine Learning
- Implementar prÃ¡cticas de MLOps con MLflow
- Optimizar performance y gestionar recursos en producciÃ³n

## ğŸ“š Estructura del Proyecto

```
AzureDatabricksWorkshop/
â”‚
â”œâ”€â”€ ğŸ“ DatabricksBasico/                    # Nivel 1: Fundamentos
â”‚   â”œâ”€â”€ Laboratorio 1: CreaciÃ³n de Workspace
â”‚   â”œâ”€â”€ Laboratorio 2: CreaciÃ³n de Cluster y Primer Notebook
â”‚   â”œâ”€â”€ Laboratorio 3: Carga y ExploraciÃ³n de Datos
â”‚   â”œâ”€â”€ Laboratorio 4: Procesamiento de Datos con Spark
â”‚   â”œâ”€â”€ Laboratorio Preparatorio: Azure Storage Account
â”‚   â”œâ”€â”€ Â¿Por quÃ© guardar datos en formato Delta Lake?
â”‚   â””â”€â”€ PolÃ­ticas de clÃºster predefinidas
â”‚
â”œâ”€â”€ ğŸ“ DatabricksIntermedio/                # Nivel 2: Intermedio
â”‚   â”œâ”€â”€ Laboratorio 1: ConfiguraciÃ³n de Seguridad y Roles
â”‚   â”œâ”€â”€ Laboratorio 2: Pipeline de Ingesta con Auto Loader
â”‚   â”œâ”€â”€ Laboratorio 3: AlmacÃ©n Delta con Versionado
â”‚   â”œâ”€â”€ Laboratorio 4: Tuning de Performance en Spark
â”‚   â”œâ”€â”€ Laboratorio 5: Entrenamiento y Deploy con MLflow
â”‚   â”œâ”€â”€ Laboratorio 6: OrquestaciÃ³n con Databricks Workflows
â”‚   â”œâ”€â”€ Caching y Persistencia en Spark
â”‚   â”œâ”€â”€ Lazy Evaluation en Spark
â”‚   â””â”€â”€ Spark Execution Plan y Catalyst Optimizer
â”‚
â”œâ”€â”€ ğŸ“ DatabricksAvanzado/                  # Nivel 3: Avanzado
â”‚   â”œâ”€â”€ Lab 1: Seguridad y Monitoreo
â”‚   â”œâ”€â”€ Lab 2: Pipeline Streaming con Kafka
â”‚   â”œâ”€â”€ Lab 3: Arquitectura Lakehouse
â”‚   â”œâ”€â”€ Lab 4: OptimizaciÃ³n de Jobs Spark
â”‚   â”œâ”€â”€ Lab 5: MLOps con MLflow y DevOps
â”‚   â”œâ”€â”€ Lab 6: OrquestaciÃ³n de Workflows
â”‚   â”œâ”€â”€ Lab 7: AnÃ¡lisis con MLflow
â”‚   â”œâ”€â”€ Lab 8: ConfiguraciÃ³n Ramas Databricks-GitHub
â”‚   â””â”€â”€ Lab 9-11: Cluster Avanzado (Partes 1-3)
â”‚
â””â”€â”€ ğŸ“ FundamentosArquitecturaAzureDatabricks/   # Serie especializada
    â”œâ”€â”€ Lab 1: Fundamentos de Arquitectura
    â”œâ”€â”€ Lab 3: Feature Engineering y ExploraciÃ³n de Datos
    â”œâ”€â”€ Lab 4: Entrenamiento y Registro de Modelos con MLflow
    â””â”€â”€ owid-energy-data.csv (Dataset de ejemplo)
```

## ğŸš€ GuÃ­a de Inicio RÃ¡pido

### Prerrequisitos

- **Cuenta de Azure** con permisos para crear recursos
- **Azure Databricks Workspace** activo
- **Conocimientos bÃ¡sicos** de:
  - Python
  - SQL
  - Conceptos de Machine Learning
  - Big Data (recomendado)

### InstalaciÃ³n

1. **Clonar el repositorio:**
   ```bash
   git clone https://github.com/alemcuevas/AzureDatabricksWorkshop.git
   cd AzureDatabricksWorkshop
   ```

2. **Configurar Azure Databricks:**
   - Sigue el `Laboratorio Preparatorio` en DatabricksBasico
   - Crea un workspace en Azure Portal
   - Configura un cluster de Databricks

3. **Importar notebooks:**
   - Sube los archivos `.ipynb` a tu workspace de Databricks
   - O utiliza la integraciÃ³n con Git (ver Lab 8 - Avanzado)

## ğŸ“– Rutas de Aprendizaje

### ğŸŸ¢ Ruta 1: Principiante (2-3 semanas)

**Objetivo:** Fundamentos de Databricks y Spark

1. **DatabricksBasico** - Completar todos los laboratorios (1-4)
2. **FundamentosArquitecturaAzureDatabricks/Lab1** - Arquitectura bÃ¡sica
3. PrÃ¡ctica: Crear tu primer pipeline de datos

**DuraciÃ³n estimada:** 15-20 horas

### ğŸŸ¡ Ruta 2: Intermedio (3-4 semanas)

**Objetivo:** Pipelines de producciÃ³n y ML

1. **DatabricksIntermedio** - Laboratorios 1-6
2. **FundamentosArquitecturaAzureDatabricks/Lab3-4** - Feature Engineering y MLflow
3. Conceptos avanzados: Caching, Lazy Evaluation, Catalyst Optimizer
4. Proyecto: Pipeline completo de ML

**DuraciÃ³n estimada:** 25-30 horas

### ğŸ”´ Ruta 3: Avanzado (4-6 semanas)

**Objetivo:** MLOps y arquitecturas empresariales

1. **DatabricksAvanzado** - Labs 1-11
2. Implementar CI/CD con Azure DevOps
3. Arquitectura Lakehouse completa
4. Streaming en tiempo real con Kafka
5. Proyecto final: Sistema MLOps end-to-end

**DuraciÃ³n estimada:** 35-40 horas

## ğŸ“ Laboratorios Destacados

### ğŸ“Š Lab 3: Feature Engineering y ExploraciÃ³n de Datos

**DuraciÃ³n:** 1 hora | **Nivel:** Intermedio

Aprende a desarrollar pipelines reproducibles de features para modelos de ML:
- EDA con Pandas y Spark
- CreaciÃ³n de variables derivadas
- ImputaciÃ³n y encoding
- Persistencia en Delta Lake
- Control de data drift

**Archivos:**
- `FundamentosArquitecturaAzureDatabricks/Lab3_Feature_Engineering_Exploracion_Datos.ipynb`
- `FundamentosArquitecturaAzureDatabricks/Lab3_Feature_Engineering_Exploracion_Datos.md`

### ğŸ¤– Lab 4: Entrenamiento y Registro de Modelos con MLflow

**DuraciÃ³n:** 1 hora | **Nivel:** Intermedio

Domina MLflow para gestionar el ciclo de vida completo de modelos ML:
- ConfiguraciÃ³n de experimentos
- Tracking de mÃ©tricas y parÃ¡metros
- Model Registry y versionado
- ComparaciÃ³n de modelos
- BÃºsqueda de hiperparÃ¡metros
- Deployment desde Registry

**Archivos:**
- `FundamentosArquitecturaAzureDatabricks/Lab4_Entrenamiento_Registro_Modelos_MLflow.ipynb`
- `FundamentosArquitecturaAzureDatabricks/Lab4_Entrenamiento_Registro_Modelos_MLflow.md`

### ğŸ—ï¸ Lab 3 Avanzado: Arquitectura Lakehouse

**DuraciÃ³n:** 2 horas | **Nivel:** Avanzado

Implementa una arquitectura Lakehouse moderna:
- Bronze, Silver, Gold layers
- Medallion Architecture
- Data governance
- Performance optimization

**Archivo:**
- `DatabricksAvanzado/Lab3_Arquitectura_Lakehouse.ipynb`

### ğŸ”„ Lab 5 Avanzado: MLOps con MLflow y DevOps

**DuraciÃ³n:** 2 horas | **Nivel:** Avanzado

Integra MLflow con Azure DevOps para pipelines CI/CD:
- AutomatizaciÃ³n de entrenamiento
- Testing de modelos
- Deployment continuo
- Monitoreo en producciÃ³n

**Archivo:**
- `DatabricksAvanzado/Lab5_MLOps_MLflow_DevOps.ipynb`

## ğŸ› ï¸ TecnologÃ­as Utilizadas

| TecnologÃ­a | DescripciÃ³n | Uso en el Workshop |
|------------|-------------|-------------------|
| **Azure Databricks** | Plataforma de anÃ¡lisis unificada | Entorno principal de desarrollo |
| **Apache Spark** | Motor de procesamiento distribuido | Procesamiento de Big Data |
| **PySpark** | API Python para Spark | AnÃ¡lisis y transformaciÃ³n de datos |
| **Delta Lake** | Capa de almacenamiento ACID | GestiÃ³n de datos confiable |
| **MLflow** | Plataforma MLOps | Tracking, registro y deployment de modelos |
| **Pandas** | LibrerÃ­a de anÃ¡lisis de datos | EDA y manipulaciÃ³n de datos |
| **Scikit-learn** | Framework de Machine Learning | Algoritmos y mÃ©tricas de ML |
| **Matplotlib/Seaborn** | VisualizaciÃ³n de datos | GrÃ¡ficos y anÃ¡lisis visual |
| **Apache Kafka** | Streaming de eventos | Pipelines en tiempo real |
| **Azure DevOps** | CI/CD y gestiÃ³n de proyectos | AutomatizaciÃ³n y MLOps |

## ğŸ“Š Dataset de Ejemplo

El workshop utiliza el dataset **Our World in Data - Energy** (`owid-energy-data.csv`) que contiene:

- ğŸŒ Datos de consumo energÃ©tico mundial
- ğŸ“… Series temporales por paÃ­s y aÃ±o
- âš¡ Variables de energÃ­as renovables y fÃ³siles
- ğŸŒ± Emisiones de gases de efecto invernadero
- ğŸ“ˆ Indicadores econÃ³micos (GDP, poblaciÃ³n)

**Ideal para:**
- Feature engineering
- AnÃ¡lisis de series temporales
- Modelos de clasificaciÃ³n y regresiÃ³n
- Visualizaciones interactivas

## ğŸ’¡ Mejores PrÃ¡cticas Implementadas

### ğŸ“ CÃ³digo
- âœ… Notebooks bien documentados con markdown
- âœ… CÃ³digo modular y reutilizable
- âœ… Funciones parametrizadas
- âœ… Manejo de errores

### ğŸ”’ Seguridad
- âœ… Control de acceso basado en roles (RBAC)
- âœ… Secrets management con Azure Key Vault
- âœ… Network isolation
- âœ… AuditorÃ­a y logging

### ğŸš€ Performance
- âœ… Particionamiento de datos
- âœ… Caching estratÃ©gico
- âœ… Broadcast joins
- âœ… OptimizaciÃ³n de Spark SQL

### ğŸ”„ MLOps
- âœ… Versionado de modelos
- âœ… Reproducibilidad con MLflow
- âœ… CI/CD pipelines
- âœ… Monitoreo de drift

## ğŸ¯ Casos de Uso Cubiertos

1. **Data Engineering**
   - ETL/ELT pipelines
   - Data quality checks
   - Incremental processing
   - Change Data Capture (CDC)

2. **Data Science**
   - Exploratory Data Analysis (EDA)
   - Feature engineering
   - Model training y tuning
   - A/B testing

3. **Machine Learning Operations**
   - Experiment tracking
   - Model registry
   - Automated deployment
   - Model monitoring

4. **Real-time Analytics**
   - Streaming ingestion
   - Real-time transformations
   - Event-driven architectures

## ğŸ¤ ContribuciÃ³n

Â¡Las contribuciones son bienvenidas! Si deseas mejorar este workshop:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

### GuÃ­as de ContribuciÃ³n

- MantÃ©n el formato y estructura existente
- Documenta claramente los nuevos laboratorios
- Incluye ejemplos prÃ¡cticos y casos de uso
- Actualiza el README si es necesario

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## ğŸ‘¥ Autor

**Alejandro Cuevas** - [@alemcuevas](https://github.com/alemcuevas)

## ğŸ™ Agradecimientos

- Comunidad de Azure Databricks
- DocumentaciÃ³n oficial de Apache Spark
- Equipo de MLflow
- Contribuidores y estudiantes del workshop

## ğŸ“ Soporte y Contacto

- ğŸ“§ **Issues:** [GitHub Issues](https://github.com/alemcuevas/AzureDatabricksWorkshop/issues)
- ğŸ’¬ **Discusiones:** [GitHub Discussions](https://github.com/alemcuevas/AzureDatabricksWorkshop/discussions)
- ğŸ“š **Wiki:** [Project Wiki](https://github.com/alemcuevas/AzureDatabricksWorkshop/wiki)

## ğŸ—ºï¸ Roadmap

### En Desarrollo
- [ ] Lab 2: Data Quality Framework
- [ ] Lab 5: AutoML con Databricks
- [ ] IntegraciÃ³n con Azure Synapse Analytics
- [ ] MÃ³dulo de Deep Learning con TensorFlow

### Planeado
- [ ] Workshop en video
- [ ] Certificaciones recomendadas
- [ ] Casos de uso por industria
- [ ] Templates de proyectos

---

â­ **Si este workshop te resulta Ãºtil, considera darle una estrella en GitHub** â­

## ğŸ“ˆ Estado del Proyecto

![GitHub last commit](https://img.shields.io/github/last-commit/alemcuevas/AzureDatabricksWorkshop)
![GitHub issues](https://img.shields.io/github/issues/alemcuevas/AzureDatabricksWorkshop)
![GitHub stars](https://img.shields.io/github/stars/alemcuevas/AzureDatabricksWorkshop)
![GitHub forks](https://img.shields.io/github/forks/alemcuevas/AzureDatabricksWorkshop)

**Ãšltima actualizaciÃ³n:** Diciembre 2025  
**VersiÃ³n:** 1.0.0  
**Estado:** Activo y en continuo desarrollo

---

<div align="center">
  <strong>Happy Learning! ğŸš€ğŸ“ŠğŸ¤–</strong>
</div>