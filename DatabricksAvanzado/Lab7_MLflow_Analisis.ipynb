{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83e\uddea Laboratorio Extra: An\u00e1lisis Completo con MLflow\n",
        "\n",
        "## \ud83c\udfaf Objetivo\n",
        "\n",
        "Realizar un an\u00e1lisis exhaustivo de experimentos de machine learning registrados con MLflow, incluyendo comparaci\u00f3n de m\u00e9tricas, visualizaci\u00f3n de resultados, y selecci\u00f3n del mejor modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u2139\ufe0f Introducci\u00f3n\n",
        "\n",
        "MLflow permite realizar experimentaci\u00f3n reproducible y trazable en proyectos de machine learning.\n",
        "Este laboratorio te gu\u00eda paso a paso en el uso del tracking server para analizar m\u00faltiples ejecuciones de modelos, visualizar m\u00e9tricas, y seleccionar la mejor versi\u00f3n basada en resultados objetivos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83e\udde0 Conceptos Clave\n",
        "\n",
        "**Experimentos MLflow**\n",
        "Una colecci\u00f3n de ejecuciones (runs) relacionadas. Cada ejecuci\u00f3n tiene par\u00e1metros, m\u00e9tricas, artefactos y modelos.\n",
        "\n",
        "**Run**\n",
        "Instancia \u00fanica de entrenamiento registrada con MLflow. Puede incluir c\u00f3digo, m\u00e9tricas, modelos y otros artefactos.\n",
        "\n",
        "**Comparaci\u00f3n de Runs**\n",
        "MLflow permite comparar ejecuciones dentro de un experimento mediante m\u00e9tricas registradas, visualizaciones y filtros.\n",
        "[\ud83d\udcd8 Ver documentaci\u00f3n](https://mlflow.org/docs/latest/tracking.html#viewing-the-tracking-ui)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83e\uddfe \u00bfPor qu\u00e9 es importante analizar experimentos en MLflow?\n",
        "\n",
        "El an\u00e1lisis de m\u00faltiples ejecuciones de modelos permite identificar qu\u00e9 combinaciones de par\u00e1metros producen los mejores resultados. Sin este an\u00e1lisis sistem\u00e1tico, es f\u00e1cil perder de vista qu\u00e9 cambios impactan en el rendimiento del modelo.\n",
        "\n",
        "MLflow ofrece una interfaz que facilita este an\u00e1lisis con:\n",
        "- Visualizaciones autom\u00e1ticas de m\u00e9tricas.\n",
        "- Filtros por par\u00e1metros o etiquetas.\n",
        "- Comparaci\u00f3n visual de runs.\n",
        "- Capacidad de registrar modelos y promoverlos.\n",
        "\n",
        "Este laboratorio refleja un flujo profesional de trabajo en experimentaci\u00f3n de modelos y es aplicable tanto en entornos acad\u00e9micos como productivos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udee0\ufe0f Pasos del laboratorio\n",
        "\n",
        "### 1. Entrenar varios modelos con distintos par\u00e1metros y registrarlos en MLflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "mlflow.set_experiment(\"Iris_RF_Analysis\")\n",
        "\n",
        "for n_estimators in [10, 50, 100, 200]:\n",
        "    with mlflow.start_run():\n",
        "        clf = RandomForestClassifier(n_estimators=n_estimators)\n",
        "        clf.fit(X_train, y_train)\n",
        "        preds = clf.predict(X_test)\n",
        "        acc = accuracy_score(y_test, preds)\n",
        "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "        mlflow.log_metric(\"accuracy\", acc)\n",
        "        mlflow.sklearn.log_model(clf, \"model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udca1 Buenas pr\u00e1cticas para el an\u00e1lisis con MLflow\n",
        "\n",
        "- **Consistencia**: Aseg\u00farate de registrar los mismos tipos de m\u00e9tricas y par\u00e1metros para todas las ejecuciones.\n",
        "- **Etiquetado**: Usa `mlflow.set_tags()` o el UI para clasificar ejecuciones por tipo de experimento o autor.\n",
        "- **Versionamiento**: Usa `Model Registry` para tener control sobre qu\u00e9 modelos est\u00e1n listos para producci\u00f3n.\n",
        "- **Trazabilidad**: Guarda scripts, visualizaciones o m\u00e9tricas adicionales como artefactos adjuntos a cada run.\n",
        "\n",
        "Estas pr\u00e1cticas permiten colaborar mejor en equipos de ciencia de datos y escalar tus soluciones de ML con gobernanza y seguridad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Usar MLflow UI para explorar el experimento\n",
        "- Ve a la interfaz web de MLflow en Databricks.\n",
        "- Navega a la secci\u00f3n de experimentos.\n",
        "- Aplica filtros por par\u00e1metros (por ejemplo, `n_estimators > 50`).\n",
        "- Ordena las ejecuciones por m\u00e9trica de `accuracy`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Comparar ejecuciones con gr\u00e1ficas en MLflow\n",
        "- Usa el bot\u00f3n **Compare**.\n",
        "- Selecciona hasta 10 ejecuciones.\n",
        "- Visualiza la m\u00e9trica `accuracy` para comparar desempe\u00f1o.\n",
        "- Examina el c\u00f3digo fuente, par\u00e1metros y modelos registrados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Seleccionar y promover el mejor modelo\n",
        "- Desde la UI de MLflow, selecciona el run con mejor `accuracy`.\n",
        "- Reg\u00edstralo en el **Model Registry** como nueva versi\u00f3n.\n",
        "- Promu\u00e9velo a etapa `Staging` o `Production` para su uso.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u2705 Validaci\u00f3n\n",
        "- Aseg\u00farate de tener m\u00faltiples ejecuciones visibles en el experimento.\n",
        "- Confirma que las m\u00e9tricas est\u00e9n graficadas correctamente.\n",
        "- Verifica que el mejor modelo est\u00e9 registrado en el Model Registry.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}