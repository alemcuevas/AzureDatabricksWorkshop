{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c90bc476-c6c7-4683-8a2e-3447d7c86a81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# âž• ExtensiÃ³n: OptimizaciÃ³n de Consultas y ComparaciÃ³n\n",
    "\n",
    "## ðŸŽ¯ Objetivo\n",
    "\n",
    "Complementar el laboratorio anterior evaluando el impacto de la cachÃ©, el broadcast join y Adaptive Query Execution (AQE) en una tarea prÃ¡ctica de anÃ¡lisis y agregaciÃ³n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a29eae6-a2f9-411b-829e-379cc665c6ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ðŸ§  TÃ©cnicas de optimizaciÃ³n incluidas\n",
    "- ComparaciÃ³n de tiempo de ejecuciÃ³n con y sin cachÃ©\n",
    "- Uso de `persist(StorageLevel.DISK_ONLY)` para pruebas controladas\n",
    "- Control de broadcast join y AQE dinÃ¡micamente\n",
    "- AnÃ¡lisis del plan de ejecuciÃ³n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd846cab-0e67-4c14-a5c0-904cf6f76ffe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importar StorageLevel para control de persistencia\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql.functions import col\n",
    "from time import time\n",
    "\n",
    "# Crear dataset base\n",
    "df_base = spark.range(0, 50_000_000).withColumn(\"mod\", (col(\"id\") % 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e092fe54-2720-4419-aaf1-6d8f92205209",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ðŸ” Experimento A: Sin cachÃ© ni optimizaciÃ³n\n",
    "Medimos el tiempo de un `groupBy().count()` sin ninguna persistencia ni AQE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0171209-7e82-4f90-b888-8a590f493bc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "df_base.groupBy(\"mod\").count().collect()\n",
    "print(f\"Tiempo sin cachÃ© ni AQE: {round(time() - start, 2)} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4494dbdc-8825-4503-833e-6d8c969c66a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## âš™ï¸ Activar AQE y cachÃ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "106b5850-13b0-4a4c-9749-f6541ecfbcfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.adaptive.enabled\", True)\n",
    "df_base.cache().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2aef7463-b672-45f0-a48d-2f8102bb18ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ðŸ” Experimento B: Con cachÃ© y AQE activado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "865e2d5b-4220-43f3-b1fb-7b879113afa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "df_base.groupBy(\"mod\").count().collect()\n",
    "print(f\"Tiempo con cachÃ© y AQE: {round(time() - start, 2)} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce893598-2dd8-4faf-89e9-bed600d5879b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "En escenarios de datasets moderados y clusters sin alta carga, tÃ©cnicas como cache() o AQE pueden no mostrar mejoras inmediatas y, de hecho, introducir ligero overhead por su inicializaciÃ³n.\n",
    "Sin embargo, su verdadero valor se evidencia cuando el dataset es consultado mÃºltiples veces, o en pipelines complejos donde evitar recomputaciones es crÃ­tico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "894a9ad6-4623-4003-9baf-c762ec2ae06d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Objetivo\n",
    "Demostrar cÃ³mo el uso de `cache()` y `Adaptive Query Execution` mejora el rendimiento cuando un DataFrame se reutiliza mÃºltiples veces en operaciones pesadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38503901-7555-4efa-a9d1-487863728773",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generar un DataFrame con datos sintÃ©ticos de 100 millones de registros\n",
    "from pyspark.sql.functions import rand\n",
    "df = spark.range(0, 100_000_000).withColumn(\"value\", rand())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de37e058-69f5-4efd-a658-97c6a5a2f427",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Caso A: Sin cachÃ©, sin AQE (tres agregaciones secuenciales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b3ed0fc-bd04-4864-b94d-a3989e5df888",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.adaptive.enabled\", False)\n",
    "import time\n",
    "start = time.time()\n",
    "df.filter(\"value > 0.9\").count()\n",
    "df.groupBy((df.id % 100)).count().collect()\n",
    "df.filter(\"value < 0.1\").agg({\"value\": \"avg\"}).collect()\n",
    "print(f\" Tiempo total sin cachÃ© ni AQE: {round(time.time() - start, 2)} seg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd31b25a-e452-43f2-b0b3-24377716a17d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Caso B: Con cachÃ© y AQE, para evitar recomputaciones y optimizar joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4c2a83d-b2b5-4bfa-8abf-1ea758dba545",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.cache().count()  # Forzar persistencia en memoria\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", True)\n",
    "start = time.time()\n",
    "df.filter(\"value > 0.9\").count()\n",
    "df.groupBy((df.id % 100)).count().collect()\n",
    "df.filter(\"value < 0.1\").agg({\"value\": \"avg\"}).collect()\n",
    "print(f\" Tiempo total con cachÃ© y AQE: {round(time.time() - start, 2)} seg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96c1377e-4c98-41bd-b774-925c812a4b72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Con `cache()` y AQE activado, las operaciones que reutilizan el DataFrame se benefician al no recalcular el plan lÃ³gico desde cero ni volver a leer datos de disco.\n",
    "Este ejemplo simula un patrÃ³n real de exploraciÃ³n de datos masiva en pipelines de anÃ¡lisis iterativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaa3fefe-fa8f-45c0-a6ee-60effe33256f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## âœ… ComparaciÃ³n final\n",
    "- Revisa Spark UI para ver diferencias en el plan fÃ­sico.\n",
    "- Compara tiempo de ejecuciÃ³n y stages utilizados.\n",
    "- Observa si hubo broadcast joins no deseados.\n",
    "\n",
    "Este mini proyecto demuestra cÃ³mo pequeÃ±as configuraciones pueden mejorar significativamente el rendimiento sin necesidad de escalar el cluster."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Lab10_Databricks_Cluster_Avanzado_Parte2",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
