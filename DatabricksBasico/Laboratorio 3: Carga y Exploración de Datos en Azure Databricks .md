# ğŸ§ª Laboratorio 3: Carga y ExploraciÃ³n de Datos en Azure Databricks

## ğŸ¯ Objetivo  
Conectar Azure Databricks a Azure Data Lake Storage Gen2 usando la clave de acceso, cargar el dataset `energy-consumption-by-source.csv`, explorarlo y guardarlo en formato Delta Lake.

---

## ğŸ•’ DuraciÃ³n estimada  
45 minutos

---

## âœ… Prerrequisitos  
- Workspace de Azure Databricks activo  
- ClÃºster en estado **Running**  
- Archivo `energy-consumption-by-source.csv` subido al contenedor `energia` del Storage Account `storageenergydemo`  
- Clave de acceso disponible desde el portal de Azure

---

## ğŸ“ Pasos

### 1. Establecer la clave de acceso en la configuraciÃ³n de Spark

Reemplaza los valores `<storage_account>` y `<access_key>` con los reales:

    spark.conf.set(
        "fs.azure.account.key.storageenergydemo.dfs.core.windows.net",
        "<clave_de_acceso>"
    )

ğŸ“¸ **Screenshot sugerido:** Celda con `spark.conf.set` ejecutada sin errores

---

### 2. Cargar el archivo CSV en un DataFrame

    df = spark.read.option("header", True).csv("abfss://energia@storageenergydemo.dfs.core.windows.net/energy-consumption-by-source.csv")
    display(df)

ğŸ“¸ **Screenshot sugerido:** Primeras filas del DataFrame cargado correctamente

---

### 3. Explorar los datos

- Ver el esquema:

        df.printSchema()

- Mostrar paÃ­ses Ãºnicos:

        df.select("Entity").distinct().show(10)

- Filtrar datos por paÃ­s (ejemplo: MÃ©xico):

        df.filter(df.Entity == "Mexico").display()

ğŸ“¸ **Screenshot sugerido:** Resultados del filtro por paÃ­s

---

### 4. Guardar los datos en formato Delta

    df.write.format("delta").mode("overwrite").save("abfss://energia@storageenergydemo.dfs.core.windows.net/delta/energy-data")

ğŸ“¸ **Screenshot sugerido:** ConfirmaciÃ³n de escritura exitosa

---

### 5. Leer los datos desde Delta Lake

    df_delta = spark.read.format("delta").load("abfss://energia@storageenergydemo.dfs.core.windows.net/delta/energy-data")
    display(df_delta)

ğŸ“¸ **Screenshot sugerido:** Vista de los datos cargados en formato Delta

---

### 6. Ejecutar una consulta SQL

1. Registrar una vista temporal:

        df_delta.createOrReplaceTempView("energia")

2. Ejecutar la siguiente consulta para ver los 10 paÃ­ses con mayor consumo energÃ©tico en 2020:

        %sql
        SELECT Entity, Year, `Primary energy consumption`
        FROM energia
        WHERE Year = 2020
        ORDER BY `Primary energy consumption` DESC
        LIMIT 10

ğŸ“¸ **Screenshot sugerido:** Tabla con resultados ordenados

---

## ğŸ§  Conceptos clave aplicados

- ConexiÃ³n directa a ADLS Gen2 vÃ­a `spark.conf.set`  
- Lectura y visualizaciÃ³n de archivos CSV en Databricks  
- Almacenamiento optimizado con Delta Lake  
- AnÃ¡lisis exploratorio con SQL sobre Spark

---

## ğŸ“š Recursos Oficiales Recomendados

- [Leer datos desde Azure Data Lake Gen2](https://learn.microsoft.com/azure/databricks/data/data-sources/azure/azure-datalake-gen2)  
- [DocumentaciÃ³n oficial de Delta Lake](https://learn.microsoft.com/azure/databricks/delta/)  
- [Conexiones seguras con claves](https://learn.microsoft.com/azure/databricks/data/data-sources/azure/azure-storage#--access-using-an-account-key)  
- [Consultas SQL en Databricks](https://learn.microsoft.com/azure/databricks/sql/)

ğŸ’¡ **Consejo:** Usa esta opciÃ³n solo en entornos de desarrollo. Para producciÃ³n, se recomienda usar **Azure Key Vault** o **Managed Identity** para mayor seguridad.
