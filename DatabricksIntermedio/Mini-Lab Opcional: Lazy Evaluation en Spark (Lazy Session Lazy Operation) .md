## ğŸ§ª Mini-Lab Opcional: Lazy Evaluation en Spark (Lazy Session / Lazy Operation)

### ğŸ¯ Objetivo
Demostrar cÃ³mo funciona la **ejecuciÃ³n diferida (lazy evaluation)** en Spark dentro de Azure Databricks, y cÃ³mo afecta al rendimiento y flujo de trabajo.

---

### ğŸ§  Â¿QuÃ© es Lazy Evaluation?

En Spark, todas las transformaciones sobre un DataFrame (como `.select()`, `.filter()`, `.withColumn()`, etc.) **no se ejecutan inmediatamente**. Spark construye un plan lÃ³gico que se ejecuta **solo cuando se necesita un resultado final**, como con `.show()`, `.count()`, `.collect()`, etc.

Esto se conoce como **evaluaciÃ³n diferida** o **lazy evaluation**.

---

### ğŸš¶â€â™‚ï¸ Pasos del Mini-Lab

#### Paso 1: Crear un DataFrame simple

df = spark.range(1, 1000000)

Este comando solo define el plan lÃ³gico. No ejecuta nada aÃºn.

---

#### Paso 2: Agregar transformaciones encadenadas

df_transformed = df.withColumn("doble", df["id"] * 2).filter("doble % 5 == 0")

Nuevamente, **no se ejecuta nada todavÃ­a**. Spark sigue construyendo el plan de ejecuciÃ³n.

---

#### Paso 3: Ejecutar una acciÃ³n para forzar la ejecuciÃ³n

df_transformed.count()

AquÃ­ Spark ejecuta todo el pipeline anterior: crea el rango, aplica la columna, filtra, y cuenta los resultados. Solo ahora se inicia el trabajo real.

---

### ğŸ” Observaciones

- Puedes abrir el **Spark UI** despuÃ©s de `.count()` para ver que el trabajo se ejecutÃ³ completo en ese momento.
- Si haces mÃ¡s transformaciones pero no llamas a ninguna acciÃ³n, **Spark no hace nada hasta que lo necesite**.

---

### âœ… ConclusiÃ³n

La lazy evaluation permite que Spark:

- Optimice el plan de ejecuciÃ³n completo antes de correrlo
- Evite trabajo innecesario
- Combine transformaciones para ejecutarlas de forma mÃ¡s eficiente

---

### ğŸ’¡ Consejo

Para forzar una ejecuciÃ³n y evaluar rendimiento o resultados, usa acciones como:

- `.show()`
- `.count()`
- `.collect()`
- `.write()`

Evita asumir que algo ya se ejecutÃ³ solo por haber definido un DataFrame.

---

