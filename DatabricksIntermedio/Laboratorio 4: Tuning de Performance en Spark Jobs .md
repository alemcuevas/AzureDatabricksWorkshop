# üß™ Laboratorio 4: Tuning de Performance en Spark Jobs

## üéØ Objetivo  
Aplicar t√©cnicas de optimizaci√≥n en Spark: uso de cache, particionamiento eficiente, y ajuste din√°mico de planes de ejecuci√≥n con Adaptive Query Execution (AQE).

---

## üïí Duraci√≥n estimada  
45 minutos

---

## ‚úÖ Prerrequisitos  
- Laboratorio 3 completado  
- Datos disponibles en la capa Silver:  
  `abfss://silver@storageenergydemo.dfs.core.windows.net/energy`  
- Cl√∫ster en estado **Running**, preferentemente con Databricks Runtime 8.4 o superior

---

## üìù Pasos

### 1. Leer los datos de Silver

    df = spark.read.format("delta").load("abfss://silver@storageenergydemo.dfs.core.windows.net/energy")
    display(df)

---

## üß† ¬øQu√© es Adaptive Query Execution (AQE)?

**Adaptive Query Execution (AQE)** es una funcionalidad de Apache Spark que permite **optimizar el plan de ejecuci√≥n de una consulta en tiempo real**, es decir, mientras se est√° ejecutando. Esto mejora el rendimiento autom√°ticamente sin necesidad de que el usuario ajuste configuraciones manualmente.

---

### ‚úÖ ¬øQu√© hace AQE?

- **Reoptimiza el plan de ejecuci√≥n** bas√°ndose en estad√≠sticas reales observadas durante el runtime
- Mejora la eficiencia de **joins, agregaciones y particiones**
- Puede reducir significativamente el tiempo de ejecuci√≥n de ciertas consultas complejas

---

### üõ† Caracter√≠sticas principales

1. **Join Reordering**  
   Cambia din√°micamente el orden de los joins para que las tablas peque√±as se usen primero.

2. **Join Strategy Switching**  
   Cambia autom√°ticamente entre broadcast join y sort merge join dependiendo del tama√±o real de los datos.

3. **Dynamic Partition Coalescing**  
   Une particiones peque√±as generadas por shuffle para evitar sobrecarga de tareas.

---

### üöÄ C√≥mo activar AQE

AQE viene desactivado por defecto en algunas versiones. Para activarlo dentro de un notebook de Databricks:

**Configuraci√≥n recomendada:**

spark.conf.set("spark.sql.adaptive.enabled", "true")

Tambi√©n puedes activar configuraciones espec√≠ficas como:

spark.conf.set("spark.sql.adaptive.coalescePartitions.enabled", "true")

spark.conf.set("spark.sql.adaptive.skewJoin.enabled", "true")

---

### üìä ¬øC√≥mo saber si AQE est√° funcionando?

- Puedes usar el m√©todo `.explain(True)` sobre tu DataFrame para ver un plan de ejecuci√≥n detallado.
- Tambi√©n puedes ir a la pesta√±a **Spark UI > SQL** y ver si aparece la optimizaci√≥n en tiempo de ejecuci√≥n aplicada.

---

### ‚ö†Ô∏è Consideraciones

- AQE requiere una versi√≥n moderna de Spark (3.0 en adelante)
- Aunque mejora muchas consultas, no garantiza mejoras en todos los casos
- Aseg√∫rate de no tener configuraciones de Spark que entren en conflicto con la optimizaci√≥n din√°mica

---

### üí° Consejo

Activa AQE en cl√∫steres donde se ejecutan cargas anal√≠ticas con joins o agregaciones pesadas. La optimizaci√≥n autom√°tica puede darte beneficios inmediatos sin cambiar tu l√≥gica de c√≥digo.

---

### 2. Activar Adaptive Query Execution (AQE)

    spark.conf.set("spark.sql.adaptive.enabled", "true")

‚úÖ AQE permite que Spark ajuste autom√°ticamente particiones y uniones seg√∫n estad√≠sticas observadas en tiempo de ejecuci√≥n.

---

### 3. Analizar sin optimizaci√≥n

Realiza una agregaci√≥n sin cach√© ni particionamiento:

    from pyspark.sql.functions import avg

    df.groupBy("Country").agg(avg("Primary_energy_consumption_TWh")).show(10)

![image](https://github.com/user-attachments/assets/1184ed71-1cc3-4677-a6c1-6d992a45e5e9)

---

### 4. Aplicar cache para reutilizaci√≥n

    df.cache()
    df.count()  # Obligamos materializaci√≥n del cache

Repite una consulta para observar mejora de tiempo:

    df.groupBy("Year").count().show()

![image](https://github.com/user-attachments/assets/8b799c6e-4d67-4f09-b0ac-a8a4c8e71f81)

---

### 5. Aplicar particionamiento para escritura optimizada

    df.write.format("delta") \
      .mode("overwrite") \
      .partitionBy("Year") \
      .save("abfss://silver@storageenergydemo.dfs.core.windows.net/energy_partitioned")

![image](https://github.com/user-attachments/assets/cbd32759-6296-483b-ab60-d392e801519e)

---

### 6. Consultar con filtro sobre partici√≥n

    df_part = spark.read.format("delta").load("abfss://silver@storageenergydemo.dfs.core.windows.net/energy_partitioned")
    df_part.filter("Year = 2020").display()

‚úÖ Spark ahora puede hacer **partition pruning** para leer solo archivos del a√±o 2020

## üå≤ ¬øQu√© es Partition Pruning?

**Partition Pruning** es una t√©cnica de optimizaci√≥n en Apache Spark y Azure Databricks que permite **leer solo las particiones necesarias** de una tabla cuando se aplica un filtro en una consulta. Esto mejora considerablemente el rendimiento, especialmente en tablas muy grandes.

---

### ‚úÖ ¬øC√≥mo funciona?

Si una tabla Delta est√° particionada por una columna como `Year`, y haces una consulta con un filtro como `WHERE Year = 2022`, Spark identifica autom√°ticamente que solo necesita acceder a la carpeta `Year=2022`, y **evita leer todas las dem√°s particiones**.

---

### üì¶ Ejemplo pr√°ctico

Sup√≥n que tienes una tabla Delta guardada en la siguiente ruta:

abfss://silver@storageaccount.dfs.core.windows.net/energy_partitioned

Y que esa tabla fue escrita usando `.partitionBy("Year")`.

Al ejecutar este c√≥digo:

**Leer datos particionados:**

df = spark.read.format("delta").load("abfss://silver@storageaccount.dfs.core.windows.net/energy_partitioned")

**Filtrar por a√±o:**

df.filter("Year = 2020").display()

Spark autom√°ticamente aplicar√° **partition pruning** y solo leer√° los archivos de la carpeta `/Year=2020/`.

---

### üìå Buenas pr√°cticas para aprovechar partition pruning

- Siempre que sea posible, escribe los datos con `.partitionBy("columna")` en el `DataFrameWriter`.
- Aplica filtros directos sobre columnas particionadas (por ejemplo, `Year = 2022`).
- Evita transformar la columna particionada en la consulta (por ejemplo, `YEAR(fecha)` evita el pruning).
- Puedes confirmar que el pruning se aplica usando `.explain(True)` en el DataFrame.

---

### üö´ Cosas que pueden romper el pruning

- Usar funciones como `year(fecha)` en lugar de filtrar directamente por `Year`
- No definir correctamente la columna como partici√≥n al escribir los datos
- Cargar datos sin especificar un formato particionado o sin respetar la estructura

---

### üí° Consejo

Partition pruning es especialmente √∫til en arquitecturas con particionamiento por tiempo (a√±o, mes, d√≠a) o regiones. √ösalo para minimizar el volumen de lectura y acelerar los tiempos de ejecuci√≥n en Databricks.

---

### 7. Comparar planes de ejecuci√≥n

Usa el m√©todo `.explain(True)` para visualizar el efecto de AQE:

    df.groupBy("Country").agg(avg("Primary_energy_consumption_TWh")).explain(True)

![image](https://github.com/user-attachments/assets/cbe25b8c-d9ce-43c3-b393-18c5288ecb75)

---

## üß† Conceptos clave aplicados

- Uso de `cache()` para acelerar consultas repetidas  
- Escritura con `partitionBy()` para habilitar filtros eficientes  
- Activaci√≥n de AQE para ajuste din√°mico de planes de ejecuci√≥n  
- An√°lisis de rendimiento con planes de ejecuci√≥n detallados

---

## üìö Recursos Oficiales Recomendados

- [Optimizaci√≥n con Spark Cache](https://spark.apache.org/docs/latest/sql-performance-tuning.html#caching-data)  
- [Particiones en Delta Lake](https://learn.microsoft.com/azure/databricks/delta/optimizations/file-mgmt#data-skipping)  
- [Adaptive Query Execution (AQE)](https://spark.apache.org/docs/latest/sql-performance-tuning.html#adaptive-query-execution)  
- [Databricks Performance Tuning Guide](https://learn.microsoft.com/azure/databricks/delta/performance/)

üí° **Consejo:** Estas t√©cnicas deben aplicarse una vez que se ha estabilizado el esquema de tus tablas y entiendes el patr√≥n de acceso t√≠pico.
