# ğŸ§ª Laboratorio 4: Tuning de Performance en Spark Jobs

## ğŸ¯ Objetivo  
Aplicar tÃ©cnicas de optimizaciÃ³n en Spark: uso de cache, particionamiento eficiente, y ajuste dinÃ¡mico de planes de ejecuciÃ³n con Adaptive Query Execution (AQE).

---

## ğŸ•’ DuraciÃ³n estimada  
45 minutos

---

## âœ… Prerrequisitos  
- Laboratorio 3 completado  
- Datos disponibles en la capa Silver:  
  `abfss://silver@storageenergydemo.dfs.core.windows.net/energy`  
- ClÃºster en estado **Running**, preferentemente con Databricks Runtime 8.4 o superior

---

## ğŸ“ Pasos

### 1. Leer los datos de Silver

    df = spark.read.format("delta").load("abfss://silver@storageenergydemo.dfs.core.windows.net/energy")
    display(df)

---

### 2. Activar Adaptive Query Execution (AQE)

    spark.conf.set("spark.sql.adaptive.enabled", "true")

âœ… AQE permite que Spark ajuste automÃ¡ticamente particiones y uniones segÃºn estadÃ­sticas observadas en tiempo de ejecuciÃ³n.

---

### 3. Analizar sin optimizaciÃ³n

Realiza una agregaciÃ³n sin cachÃ© ni particionamiento:

    from pyspark.sql.functions import avg

    df.groupBy("Country").agg(avg("Primary_energy_consumption_TWh")).show(10)

![image](https://github.com/user-attachments/assets/1184ed71-1cc3-4677-a6c1-6d992a45e5e9)

---

### 4. Aplicar cache para reutilizaciÃ³n

    df.cache()
    df.count()  # Obligamos materializaciÃ³n del cache

Repite una consulta para observar mejora de tiempo:

    df.groupBy("Year").count().show()

![image](https://github.com/user-attachments/assets/8b799c6e-4d67-4f09-b0ac-a8a4c8e71f81)

---

### 5. Aplicar particionamiento para escritura optimizada

    df.write.format("delta") \
      .mode("overwrite") \
      .partitionBy("Year") \
      .save("abfss://silver@storageenergydemo.dfs.core.windows.net/energy_partitioned")

![image](https://github.com/user-attachments/assets/cbd32759-6296-483b-ab60-d392e801519e)

---

### 6. Consultar con filtro sobre particiÃ³n

    df_part = spark.read.format("delta").load("abfss://silver@storageenergydemo.dfs.core.windows.net/energy_partitioned")
    df_part.filter("Year = 2020").display()

âœ… Spark ahora puede hacer **partition pruning** para leer solo archivos del aÃ±o 2020

## ğŸŒ² Â¿QuÃ© es Partition Pruning?

**Partition Pruning** es una tÃ©cnica de optimizaciÃ³n en Apache Spark y Azure Databricks que permite **leer solo las particiones necesarias** de una tabla cuando se aplica un filtro en una consulta. Esto mejora considerablemente el rendimiento, especialmente en tablas muy grandes.

---

### âœ… Â¿CÃ³mo funciona?

Si una tabla Delta estÃ¡ particionada por una columna como `Year`, y haces una consulta con un filtro como `WHERE Year = 2022`, Spark identifica automÃ¡ticamente que solo necesita acceder a la carpeta `Year=2022`, y **evita leer todas las demÃ¡s particiones**.

---

### ğŸ“¦ Ejemplo prÃ¡ctico

SupÃ³n que tienes una tabla Delta guardada en la siguiente ruta:

abfss://silver@storageaccount.dfs.core.windows.net/energy_partitioned

Y que esa tabla fue escrita usando `.partitionBy("Year")`.

Al ejecutar este cÃ³digo:

**Leer datos particionados:**

df = spark.read.format("delta").load("abfss://silver@storageaccount.dfs.core.windows.net/energy_partitioned")

**Filtrar por aÃ±o:**

df.filter("Year = 2020").display()

Spark automÃ¡ticamente aplicarÃ¡ **partition pruning** y solo leerÃ¡ los archivos de la carpeta `/Year=2020/`.

---

### ğŸ“Œ Buenas prÃ¡cticas para aprovechar partition pruning

- Siempre que sea posible, escribe los datos con `.partitionBy("columna")` en el `DataFrameWriter`.
- Aplica filtros directos sobre columnas particionadas (por ejemplo, `Year = 2022`).
- Evita transformar la columna particionada en la consulta (por ejemplo, `YEAR(fecha)` evita el pruning).
- Puedes confirmar que el pruning se aplica usando `.explain(True)` en el DataFrame.

---

### ğŸš« Cosas que pueden romper el pruning

- Usar funciones como `year(fecha)` en lugar de filtrar directamente por `Year`
- No definir correctamente la columna como particiÃ³n al escribir los datos
- Cargar datos sin especificar un formato particionado o sin respetar la estructura

---

### ğŸ’¡ Consejo

Partition pruning es especialmente Ãºtil en arquitecturas con particionamiento por tiempo (aÃ±o, mes, dÃ­a) o regiones. Ãšsalo para minimizar el volumen de lectura y acelerar los tiempos de ejecuciÃ³n en Databricks.

---

### 7. Comparar planes de ejecuciÃ³n

Usa el mÃ©todo `.explain(True)` para visualizar el efecto de AQE:

    df.groupBy("Country").agg(avg("Primary_energy_consumption_TWh")).explain(True)

![image](https://github.com/user-attachments/assets/cbe25b8c-d9ce-43c3-b393-18c5288ecb75)

---

## ğŸ§  Conceptos clave aplicados

- Uso de `cache()` para acelerar consultas repetidas  
- Escritura con `partitionBy()` para habilitar filtros eficientes  
- ActivaciÃ³n de AQE para ajuste dinÃ¡mico de planes de ejecuciÃ³n  
- AnÃ¡lisis de rendimiento con planes de ejecuciÃ³n detallados

---

## ğŸ“š Recursos Oficiales Recomendados

- [OptimizaciÃ³n con Spark Cache](https://spark.apache.org/docs/latest/sql-performance-tuning.html#caching-data)  
- [Particiones en Delta Lake](https://learn.microsoft.com/azure/databricks/delta/optimizations/file-mgmt#data-skipping)  
- [Adaptive Query Execution (AQE)](https://spark.apache.org/docs/latest/sql-performance-tuning.html#adaptive-query-execution)  
- [Databricks Performance Tuning Guide](https://learn.microsoft.com/azure/databricks/delta/performance/)

ğŸ’¡ **Consejo:** Estas tÃ©cnicas deben aplicarse una vez que se ha estabilizado el esquema de tus tablas y entiendes el patrÃ³n de acceso tÃ­pico.
