# üß™ Laboratorio 4: Tuning de Performance en Spark Jobs

## üéØ Objetivo  
Aplicar t√©cnicas de optimizaci√≥n en Spark: uso de cache, particionamiento eficiente, y ajuste din√°mico de planes de ejecuci√≥n con Adaptive Query Execution (AQE).

---

## üïí Duraci√≥n estimada  
45 minutos

---

## ‚úÖ Prerrequisitos  
- Laboratorio 3 completado  
- Datos disponibles en la capa Silver:  
  `abfss://silver@storageenergydemo.dfs.core.windows.net/energy`  
- Cl√∫ster en estado **Running**, preferentemente con Databricks Runtime 8.4 o superior

---

## üìù Pasos

### 1. Leer los datos de Silver

    df = spark.read.format("delta").load("abfss://silver@storageenergydemo.dfs.core.windows.net/energy")
    display(df)

---

### 2. Activar Adaptive Query Execution (AQE)

    spark.conf.set("spark.sql.adaptive.enabled", "true")

‚úÖ AQE permite que Spark ajuste autom√°ticamente particiones y uniones seg√∫n estad√≠sticas observadas en tiempo de ejecuci√≥n.

---

### 3. Analizar sin optimizaci√≥n

Realiza una agregaci√≥n sin cach√© ni particionamiento:

    from pyspark.sql.functions import avg

    df.groupBy("Country").agg(avg("Primary_energy_consumption_TWh")).show(10)

![image](https://github.com/user-attachments/assets/1184ed71-1cc3-4677-a6c1-6d992a45e5e9)

---

### 4. Aplicar cache para reutilizaci√≥n

    df.cache()
    df.count()  # Obligamos materializaci√≥n del cache

Repite una consulta para observar mejora de tiempo:

    df.groupBy("Year").count().show()

![image](https://github.com/user-attachments/assets/8b799c6e-4d67-4f09-b0ac-a8a4c8e71f81)

---

### 5. Aplicar particionamiento para escritura optimizada

    df.write.format("delta") \
      .mode("overwrite") \
      .partitionBy("Year") \
      .save("abfss://silver@storageenergydemo.dfs.core.windows.net/energy_partitioned")

üì∏ **Screenshot sugerido:** Tiempo de carga reducido al filtrar por a√±o

---

### 6. Consultar con filtro sobre partici√≥n

    df_part = spark.read.format("delta").load("abfss://silver@storageenergydemo.dfs.core.windows.net/energy_partitioned")
    df_part.filter("Year = 2020").display()

‚úÖ Spark ahora puede hacer **partition pruning** para leer solo archivos del a√±o 2020



---

### 7. Comparar planes de ejecuci√≥n

Usa el m√©todo `.explain(True)` para visualizar el efecto de AQE:

    df.groupBy("Country").agg(avg("Primary_energy_consumption_TWh")).explain(True)

üì∏ **Screenshot sugerido:** Plan de ejecuci√≥n con AQE activo

---

## üß† Conceptos clave aplicados

- Uso de `cache()` para acelerar consultas repetidas  
- Escritura con `partitionBy()` para habilitar filtros eficientes  
- Activaci√≥n de AQE para ajuste din√°mico de planes de ejecuci√≥n  
- An√°lisis de rendimiento con planes de ejecuci√≥n detallados

---

## üìö Recursos Oficiales Recomendados

- [Optimizaci√≥n con Spark Cache](https://spark.apache.org/docs/latest/sql-performance-tuning.html#caching-data)  
- [Particiones en Delta Lake](https://learn.microsoft.com/azure/databricks/delta/optimizations/file-mgmt#data-skipping)  
- [Adaptive Query Execution (AQE)](https://spark.apache.org/docs/latest/sql-performance-tuning.html#adaptive-query-execution)  
- [Databricks Performance Tuning Guide](https://learn.microsoft.com/azure/databricks/delta/performance/)

üí° **Consejo:** Estas t√©cnicas deben aplicarse una vez que se ha estabilizado el esquema de tus tablas y entiendes el patr√≥n de acceso t√≠pico.
